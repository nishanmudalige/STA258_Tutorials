[
  {
    "objectID": "practice/index.html",
    "href": "practice/index.html",
    "title": "STA258 Course Tutorials",
    "section": "",
    "text": "Welcome !"
  },
  {
    "objectID": "tutorials/tutorial_02.html#q1",
    "href": "tutorials/tutorial_02.html#q1",
    "title": "Tutorial 02: Descriptive Statistics",
    "section": "Q1 — Five-number summary",
    "text": "Q1 — Five-number summary\nThe five-number summary (Min, Q1, Median, Q3, Max) + IQR quickly reveals center and spread. Return a five number summary for the dataset airquality’s Ozone column. Further, return the IQR.\n\n\n\n\n\n\nNoteInfo\n\n\n\nThe five-number summary (Min, Q1, Median, Q3, Max) quickly shows center and spread. The IQR = Q3 − Q1 is robust to outliers and underlies boxplot fences (Q1 − 1.5·IQR, Q3 + 1.5·IQR). You’ll use base R functions that compute these directly for a numeric\n\n\n\n\n\n\n\n\nNotePreview\n\n\n\nRun the code below to see a preview of the dataset.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCall the base function that prints the five key stats, then on the next line return the robust spread of that same column; remember missing values.\n\n\n\n\nsummary(airquality$Ozone)\nIQR(airquality$Ozone, na.rm = TRUE)\nsummary(airquality$Ozone)\nIQR(airquality$Ozone, na.rm = TRUE)"
  },
  {
    "objectID": "tutorials/tutorial_02.html#q2",
    "href": "tutorials/tutorial_02.html#q2",
    "title": "Tutorial 02: Descriptive Statistics",
    "section": "Q2 — Mean, variance, and sd",
    "text": "Q2 — Mean, variance, and sd\nCompute Mean, Variance and Standard Deviation of airquality dataset’s Temp column.\n\n\n\n\n\n\nNoteInfo\n\n\n\nMean, variance, and standard deviation summarize center and spread. Variance and SD are in squared and original units respectively. Real-world data often has NAs; make sure your summary ignores them appropriately.\n\n\n\n\n\nPhoto by Tim Witzdam on Unsplash\n\n\n\n\n\n\n\n\nNotePreview\n\n\n\nRun the code below to see a preview of the dataset.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nConstruct a single named vector with three entries; each entry calls the corresponding base summary function with missing-value handling.\n\n\n\n\nc(\n  mean = mean(airquality$Temp, na.rm = TRUE),\n  var  = var(airquality$Temp,  na.rm = TRUE),\n  sd   = sd(airquality$Temp,   na.rm = TRUE)\n)\nc(\n  mean = mean(airquality$Temp, na.rm = TRUE),\n  var  = var(airquality$Temp,  na.rm = TRUE),\n  sd   = sd(airquality$Temp,   na.rm = TRUE)\n)"
  },
  {
    "objectID": "tutorials/tutorial_02.html#q3-grouped-summary-by-month",
    "href": "tutorials/tutorial_02.html#q3-grouped-summary-by-month",
    "title": "Tutorial 02: Descriptive Statistics",
    "section": "Q3 — Grouped summary by Month",
    "text": "Q3 — Grouped summary by Month\nCompute the mean Ozone by Month using base R. Return a named numeric vector (names are months).\n\n\n\n\n\n\nNotePreview\n\n\n\nRun the code below to see a preview of the dataset.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLearn about the function tapply().\n\n\n\n\ntapply(airquality$Ozone, airquality$Month, mean, na.rm = TRUE)\ntapply(airquality$Ozone, airquality$Month, mean, na.rm = TRUE)"
  },
  {
    "objectID": "tutorials/tutorial_02.html#q4-ggplot-boxplot-ordered-by-median-chickweight",
    "href": "tutorials/tutorial_02.html#q4-ggplot-boxplot-ordered-by-median-chickweight",
    "title": "Tutorial 02: Descriptive Statistics",
    "section": "Q4 — ggplot Boxplot ordered by median (ChickWeight)",
    "text": "Q4 — ggplot Boxplot ordered by median (ChickWeight)\nNow, we are moving on to the ChickWeight dataset which has data from an experiment on the effect of diet on early growth of chicks. Return a ggplot object that boxplots weight by Diet, with Diet reordered by the median weight. Fill in the blanks.\n\n\n\nPhoto by Karim MANJRA on Unsplash\n\n\n\n\n\n\n\n\nNoteInfo\n\n\n\nYou can reorder categories by a statistic (like the median) right inside aes() to make comparisons meaningful. In ggplot2, this is commonly done with reorder() (or forcats helpers). The layer for boxplots is geom_boxplot().\n\n\n\n\n\n\n\n\n\n\n\nMap Diet to x and weight to y; reorder x by median(weight) inside aes(…). Use geom_boxplot() for the layer.\n\n\n\n\nlibrary(ggplot2)\nggplot(\nChickWeight,\naes(x = reorder(factor(Diet), weight, FUN = median), y = weight)\n) +\ngeom_boxplot()\nlibrary(ggplot2)\nggplot(\nChickWeight,\naes(x = reorder(factor(Diet), weight, FUN = median), y = weight)\n) +\ngeom_boxplot()"
  },
  {
    "objectID": "tutorials/tutorial_02.html#q5-histogram-with-tukey-fences",
    "href": "tutorials/tutorial_02.html#q5-histogram-with-tukey-fences",
    "title": "Tutorial 02: Descriptive Statistics",
    "section": "Q5 — Histogram with Tukey fences",
    "text": "Q5 — Histogram with Tukey fences\nShow a histogram of ChickWeight$weight and add vertical lines at Q1, Q3, and the Tukey fences Q1−1.5·IQR, Q3+1.5·IQR\n\n\n\n\n\n\nNoteInfo\n\n\n\nTukey fences are statistical boundaries, used to identify potential outliers in a dataset. Data points falling outside these fences are considered outliers. Q1 − 1.5·IQR and Q3 + 1.5·IQR are Tukey fences!\n\n\n\n\n\n\n\n\nNotePreview\n\n\n\nHere is a preview of the dataset:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ngeom_vline is used to add vertical lines in the plot at certain positions.\n\n\n\n\nlibrary(ggplot2)\nqs &lt;- quantile(ChickWeight$weight, c(.25,.75))\nlo &lt;- qs[1] - 1.5*diff(qs)\nhi &lt;- qs[2] + 1.5*diff(qs)\nggplot(ChickWeight, aes(weight)) +\ngeom_histogram(bins = 12) +\ngeom_vline(xintercept = c(qs[1], qs[2], lo, hi))\nlibrary(ggplot2)\nqs &lt;- quantile(ChickWeight$weight, c(.25,.75))\nlo &lt;- qs[1] - 1.5*diff(qs)\nhi &lt;- qs[2] + 1.5*diff(qs)\nggplot(ChickWeight, aes(weight)) +\ngeom_histogram(bins = 12) +\ngeom_vline(xintercept = c(qs[1], qs[2], lo, hi))"
  },
  {
    "objectID": "tutorials/tutorial_02.html#q6-histogram-of-weight-ggplot2",
    "href": "tutorials/tutorial_02.html#q6-histogram-of-weight-ggplot2",
    "title": "Tutorial 02: Descriptive Statistics",
    "section": "Q6 — Histogram of Weight (ggplot2)",
    "text": "Q6 — Histogram of Weight (ggplot2)\nMake a histogram with ~12 bins. Store in p_hist.\n\n\n\n\n\n\nNoteInfo\n\n\n\nUse the built-in ChickWeight dataset. Plot the distribution of weight as a histogram with about 12 bins and assign the plot to`p_hist. Return a ggplot object (no printing required).\n\n\n\n\n\n\n\n\nNotePreview\n\n\n\nHere is a preview of the dataset:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCreate a ggplot using ChickWeight with weight mapped on x. Add a histogram layer with ~12 bins. Assign the plot object to p_hist.\n\n\n\n\nlibrary(ggplot2)\np_hist &lt;- ggplot(ChickWeight, aes(weight)) +\ngeom_histogram(bins = 12)\np_hist\nlibrary(ggplot2)\np_hist &lt;- ggplot(ChickWeight, aes(weight)) +\ngeom_histogram(bins = 12)\np_hist"
  },
  {
    "objectID": "tutorials/tutorial_02.html#q7-boxplot-of-weight-by-diet-ggplot2",
    "href": "tutorials/tutorial_02.html#q7-boxplot-of-weight-by-diet-ggplot2",
    "title": "Tutorial 02: Descriptive Statistics",
    "section": "Q7 — Boxplot of weight by Diet (ggplot2)",
    "text": "Q7 — Boxplot of weight by Diet (ggplot2)\nMake a boxplot of weight grouped by Diet (treat Diet as categorical). Store the plot in p_box\n\n\n\n\n\n\nNoteInfo\n\n\n\nHere is a preview of the dataset:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBuild a ggplot from ChickWeight. Map factor(Diet) to x and weight to y. Add a boxplot layer. Assign the result to p_box.\n\n\n\n\nlibrary(ggplot2)\np_box &lt;- ggplot(ChickWeight, aes(x = factor(Diet), y = weight)) +\ngeom_boxplot()\np_box\nlibrary(ggplot2)\np_box &lt;- ggplot(ChickWeight, aes(x = factor(Diet), y = weight)) +\ngeom_boxplot()\np_box"
  },
  {
    "objectID": "tutorials/tutorial_02.html#q8-scatter-with-smoother-time-vs-weight-ggplot2",
    "href": "tutorials/tutorial_02.html#q8-scatter-with-smoother-time-vs-weight-ggplot2",
    "title": "Tutorial 02: Descriptive Statistics",
    "section": "Q8 — Scatter with smoother: Time vs weight (ggplot2)",
    "text": "Q8 — Scatter with smoother: Time vs weight (ggplot2)\nBuild a scatterplot from ChickWeight mapping Time → x and weight → y. Store in p_scatter.\n\n\n\n\n\n\nNotePreview\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBuild a ggplot from ChickWeight mapping Time → x and weight → y. Add points, then a smoother (hide the SE ribbon). Assign the final plot to p_scatter.\n\n\n\n\nlibrary(ggplot2)\np_scatter &lt;- ggplot(ChickWeight, aes(Time, weight)) +\ngeom_point() +\ngeom_smooth(se = FALSE)\np_scatter\nlibrary(ggplot2)\np_scatter &lt;- ggplot(ChickWeight, aes(Time, weight)) +\ngeom_point() +\ngeom_smooth(se = FALSE)\np_scatter"
  },
  {
    "objectID": "tutorials/tutorial_01.html#q1",
    "href": "tutorials/tutorial_01.html#q1",
    "title": "Tutorial 01: Introduction to R",
    "section": "Q1 — Make the sum equal 10",
    "text": "Q1 — Make the sum equal 10\nReplace ＿ with a number so the expression evaluates to 10.\n\n\n\n\n\n\n\n\n\n\n\n\nReplace the two ＿ with 2 numbers that add up to 7.\n\n\n\n\n1 + 2 + 3 + 4\n1 + 2 + 3 + 4"
  },
  {
    "objectID": "tutorials/tutorial_01.html#q2-create-a-vector",
    "href": "tutorials/tutorial_01.html#q2-create-a-vector",
    "title": "Tutorial 01: Introduction to R",
    "section": "Q2 — Create a vector",
    "text": "Q2 — Create a vector\nMake a vector called my_vec that contains the numbers 5, 10, 15, 20.\n\n\n\n\n\n\n\n\n\nUse the c() function to combine numbers: c(1, 2, 3)\n\n\n\n\nmy_vec &lt;- c(5, 10, 15, 20)\nmy_vec &lt;- c(5, 10, 15, 20)"
  },
  {
    "objectID": "tutorials/tutorial_01.html#q3-find-the-average",
    "href": "tutorials/tutorial_01.html#q3-find-the-average",
    "title": "Tutorial 01: Introduction to R",
    "section": "Q3 — Find the average",
    "text": "Q3 — Find the average\nCompute the mean of the vector c(2, 4, 6, 8, 10).\nYour answer should be stored in a variable called avg_val.\n\n\n\n\n\n\n\n\n\nUse the mean() function: mean(c(…))\n\n\n\n\navg_val &lt;- mean(c(2, 4, 6, 8, 10))\navg_val &lt;- mean(c(2, 4, 6, 8, 10))"
  },
  {
    "objectID": "tutorials/tutorial_01.html#q4-draw-a-histogram-from-toothgrowth-type-the-full-call",
    "href": "tutorials/tutorial_01.html#q4-draw-a-histogram-from-toothgrowth-type-the-full-call",
    "title": "Tutorial 01: Introduction to R",
    "section": "Q4 — Draw a histogram from ToothGrowth (type the full call)",
    "text": "Q4 — Draw a histogram from ToothGrowth (type the full call)\nUse exactly one of these numeric columns and nothing else: len or dose\n\n\n\nPhoto by The Humble Co. on Unsplash\n\n\n\n\n\n\n\n\nNotePreview\n\n\n\nFind a preview of the ToothGrowth dataset here:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUse the hist command.\n\n\n\n\nhist(ToothGrowth$len)\nhist(ToothGrowth$len)"
  },
  {
    "objectID": "tutorials/tutorial_01.html#q5-draw-a-boxplot-from-toothgrowth-type-the-full-call",
    "href": "tutorials/tutorial_01.html#q5-draw-a-boxplot-from-toothgrowth-type-the-full-call",
    "title": "Tutorial 01: Introduction to R",
    "section": "Q5 — Draw a boxplot from ToothGrowth (type the full call)",
    "text": "Q5 — Draw a boxplot from ToothGrowth (type the full call)\nUse exactly one of these numeric columns and nothing else: len or dose\n\n\n\n\n\n\nNotePreview\n\n\n\nFind a preview of the ToothGrowth dataset here:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUse the boxplot command.\n\n\n\n\nboxplot(ToothGrowth$len)\nboxplot(ToothGrowth$len)"
  },
  {
    "objectID": "tutorials/tutorial_01.html#q6-add-a-color-to-the-histogram",
    "href": "tutorials/tutorial_01.html#q6-add-a-color-to-the-histogram",
    "title": "Tutorial 01: Introduction to R",
    "section": "Q6 — Add a color to the histogram",
    "text": "Q6 — Add a color to the histogram\nRe-draw a histogram of ToothGrowth$len and set any bar color using the col= argument.\n\n\n\n\n\n\n\n\n\nadd col as an additional argument here and give it a color of your choice.\n\n\n\n\nhist(ToothGrowth$len, col = \"steelblue\")\nhist(ToothGrowth$len, col = \"steelblue\")"
  },
  {
    "objectID": "tutorials/tutorial_01.html#q7-boxplot-make-it-horizontal",
    "href": "tutorials/tutorial_01.html#q7-boxplot-make-it-horizontal",
    "title": "Tutorial 01: Introduction to R",
    "section": "Q7 — Boxplot (make it horizontal)",
    "text": "Q7 — Boxplot (make it horizontal)\nDraw a boxplot of ToothGrowth$dose and make it horizontal using horizontal = TRUE as an argument.\n\n\n\n\n\n\n\n\n\nadd horizontal as an argument just like col from the previous question\n\n\n\n\nboxplot(ToothGrowth$dose, horizontal = TRUE)\nboxplot(ToothGrowth$dose, horizontal = TRUE)"
  },
  {
    "objectID": "tutorials/tutorial_01.html#q8-load-a-csv-as-a-dataframe",
    "href": "tutorials/tutorial_01.html#q8-load-a-csv-as-a-dataframe",
    "title": "Tutorial 01: Introduction to R",
    "section": "Q8 — Load a CSV as a DataFrame",
    "text": "Q8 — Load a CSV as a DataFrame\nLoad iris.csv into a dataframe named df.\n\n\n\nPhoto by Andrew Small on Unsplash\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUse read.csv here.\n\n\n\n\ndf &lt;- read.csv(\"iris.csv\")\ndf &lt;- read.csv(\"iris.csv\")"
  },
  {
    "objectID": "tutorials/tutorial_01.html#q9-count-rows-in-iris.csv",
    "href": "tutorials/tutorial_01.html#q9-count-rows-in-iris.csv",
    "title": "Tutorial 01: Introduction to R",
    "section": "Q9 — Count rows in iris.csv",
    "text": "Q9 — Count rows in iris.csv\nCount the number of rows in iris.csv and store them in the variable rows\n\n\n\n\n\n\n\n\n\n\n\n\nUse nrow.\n\n\n\n\ndf &lt;- read.csv(\"iris.csv\")\nrows &lt;- nrow(df)\ndf &lt;- read.csv(\"iris.csv\")\nrows &lt;- nrow(df)"
  },
  {
    "objectID": "tutorials/tutorial_01.html#q10-show-column-names",
    "href": "tutorials/tutorial_01.html#q10-show-column-names",
    "title": "Tutorial 01: Introduction to R",
    "section": "Q10 — Show column names",
    "text": "Q10 — Show column names\nPrint the column names from iris.csv\n\n\n\n\n\n\n\n\n\n\n\n\nUse names.\n\n\n\n\ndf   &lt;- read.csv(\"iris.csv\")\ncols &lt;- names(df)\ncols\ndf   &lt;- read.csv(\"iris.csv\")\ncols &lt;- names(df)\ncols"
  },
  {
    "objectID": "tutorials/tutorial_01.html#q11-print-some-of-the-data",
    "href": "tutorials/tutorial_01.html#q11-print-some-of-the-data",
    "title": "Tutorial 01: Introduction to R",
    "section": "Q11 — Print some of the data",
    "text": "Q11 — Print some of the data\nPrint the first 5 rows from iris.csv.\n\n\n\n\n\n\n\n\n\n\n\n\nUse head.\n\n\n\n\ndf &lt;- read.csv(\"iris.csv\")\nhead(df)\ndf &lt;- read.csv(\"iris.csv\")\nhead(df)"
  },
  {
    "objectID": "tutorials/tutorial_01.html#q12-make-a-histogram-from-iris.csv",
    "href": "tutorials/tutorial_01.html#q12-make-a-histogram-from-iris.csv",
    "title": "Tutorial 01: Introduction to R",
    "section": "Q12 — Make a histogram from iris.csv",
    "text": "Q12 — Make a histogram from iris.csv\nMake a histogram of the column Sepal.Length from iris.csv.\n\n\n\n\n\n\n\n\n\n\n\n\nUse hist (see Q5).\n\n\n\n\ndf &lt;- read.csv(\"iris.csv\")\nhist(df$Sepal.Length, col = \"lightgray\", main = \"Sepal.Length\", xlab = \"cm\") \ndf &lt;- read.csv(\"iris.csv\")\nhist(df$Sepal.Length, col = \"lightgray\", main = \"Sepal.Length\", xlab = \"cm\")"
  },
  {
    "objectID": "tutorials/tutorial_01.html#q2",
    "href": "tutorials/tutorial_01.html#q2",
    "title": "Tutorial 01: Introduction to R",
    "section": "Q13 — Write a function using division",
    "text": "Q13 — Write a function using division\nDefine a function called divide_nums that takes two arguments (a and b) and returns the results of:\n\na / b\nb / a\n\nBoth results should be stored in separate variables before being returned.\n\n\n\n\n\n\nNoteInfo\n\n\n\nRemember: in R, division by zero (1/0) will return Inf rather than an error.\n\n\n\n\n\n\n\n\nNoteInfo\n\n\n\nIn R, lists are written with list(a, b, c). Each element can be anything: a number, a string, or even another list.\n\n\n\n\n\n\n\n\n\n\n\nStart with: res1 &lt;- a / b res2 &lt;- b / a and then use the list command.\n\n\n\n\ndivide_nums &lt;- function(a, b) {\n  res1 &lt;- a / b\n  res2 &lt;- b / a\n  list(res1, res2)\n}\ndivide_nums &lt;- function(a, b) {\n  res1 &lt;- a / b\n  res2 &lt;- b / a\n  list(res1, res2)\n}"
  },
  {
    "objectID": "tutorials/tutorial_04.html#q1-z-critical-value",
    "href": "tutorials/tutorial_04.html#q1-z-critical-value",
    "title": "Tutorial 04: One Sample Confidence Intervals",
    "section": "Q1 — Z Critical Value",
    "text": "Q1 — Z Critical Value\nPrint the 95% 2-sided \\(Z^*\\) critical value when \\(\\alpha = 0.05\\).\n\n\n\n\n\n\nNoteInfo\n\n\n\nRemember: Critical values represent points on a distribution which play an important role in both confidence intervals and hypothesis testing. They are the cutoffs on a reference distribution that set the width of confidence intervals.\n\n\n\n\n\n\n\n\n\n\n\nUse qnorm.\n\n\n\n\nqnorm(0.975)\nqnorm(0.975)"
  },
  {
    "objectID": "tutorials/tutorial_04.html#q2-one-sample-z-confidence-interval",
    "href": "tutorials/tutorial_04.html#q2-one-sample-z-confidence-interval",
    "title": "Tutorial 04: One Sample Confidence Intervals",
    "section": "Q2 — One Sample Z Confidence Interval",
    "text": "Q2 — One Sample Z Confidence Interval\nThe penguins dataset contains measurements for 3 penguin species from the Palmer Archipelago. Use body_mass_g (grams). Assume the population SD is known: σ = 450 g. Construct a 90% Z-interval for the true mean body mass. Print c(lower, upper).\n\n\n\n\n\n\nNoteInfo\n\n\n\nWhen σ is known, the margin of error uses the standard normal critical value.\n\n\n\n\n\n\n\n\nNotePreview\n\n\n\nRun this code chunk to get a glimpse of the dataset. Feel free to change the values to visualize more/less number of rows.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNoteInfo\n\n\n\nWhen σ is known, \\[\n\\mathrm{CI}_{1-\\alpha}:\\ \\bar{x} \\pm x_{1-\\alpha/2}\\,\\frac{\\sigma}{\\sqrt{n}}.\n\\]\n\n\n\n\n\n\n\n\n\n\n\nCompute the sample mean, pair with the known σ and your Z critical value. Output c(lower, upper).\n\n\n\n\nif (!requireNamespace(\"palmerpenguins\", quietly = TRUE)) webr::install(\"palmerpenguins\")\nlibrary(palmerpenguins)\nx &lt;- na.omit(palmerpenguins::penguins$body_mass_g)\nxbar &lt;- mean(x)\nn &lt;- length(x)\nz &lt;- qnorm(0.95) # 90% two-sided\nsigma &lt;- 450\nxbar + c(-1,1) * z * sigma / sqrt(n)\nif (!requireNamespace(\"palmerpenguins\", quietly = TRUE)) webr::install(\"palmerpenguins\")\nlibrary(palmerpenguins)\nx &lt;- na.omit(palmerpenguins::penguins$body_mass_g)\nxbar &lt;- mean(x)\nn &lt;- length(x)\nz &lt;- qnorm(0.95) # 90% two-sided\nsigma &lt;- 450\nxbar + c(-1,1) * z * sigma / sqrt(n)"
  },
  {
    "objectID": "tutorials/tutorial_04.html#q3-t-critical-value",
    "href": "tutorials/tutorial_04.html#q3-t-critical-value",
    "title": "Tutorial 04: One Sample Confidence Intervals",
    "section": "Q3 — T Critical Value",
    "text": "Q3 — T Critical Value\nPlantGrowth is a dataset that contains results from an experiment to compare yields (as measured by dried weight of plants) obtained under a control and two different treatment conditions. Print the 95% two-sided t* using PlantGrowth’s weight column when \\(\\alpha = 0.05\\).\n\n\n\nPhoto by Nagy Arnold on Unsplash\n\n\n\n\n\n\n\n\nNotePreview\n\n\n\nRun this code chunk to get a glimpse of the dataset. Feel free to change the values to visualize more/less number of rows.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFind n from the weights vector and print the two-sided 95% t critical value using df = n − 1. Refer to the previous tutorial for a hint about the R command used to print t quantiles.\n\n\n\n\ndata(\"PlantGrowth\")\nn &lt;- length(PlantGrowth$weight)\nqt(0.975, df = n - 1)\ndata(\"PlantGrowth\")\nn &lt;- length(PlantGrowth$weight)\nqt(0.975, df = n - 1)"
  },
  {
    "objectID": "tutorials/tutorial_04.html#q4-one-sample-confidence-interval-for-μ-σ-unknown",
    "href": "tutorials/tutorial_04.html#q4-one-sample-confidence-interval-for-μ-σ-unknown",
    "title": "Tutorial 04: One Sample Confidence Intervals",
    "section": "Q4 — One-Sample Confidence Interval for μ (σ Unknown)",
    "text": "Q4 — One-Sample Confidence Interval for μ (σ Unknown)\nUsing PlantGrowth$weight (σ unknown), construct a 95% CI for the true mean plant weight. Give your output as a vector of the form c(lower, upper).\n\n\n\n\n\n\nNotePreview\n\n\n\nRun this code chunk to get a glimpse of the dataset. Feel free to change the values to visualize more/less number of rows.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNoteInfo\n\n\n\nWhen σ is unknown, replace with the sample SD s and use the t distribution:\n\\[\n\\mathrm{CI}_{1-\\alpha}:\\ \\bar{x} \\pm t_{1-\\alpha/2,\\;n-1}\\,\\frac{s}{\\sqrt{n}},\\ \\text{df}=n-1.\n\\]\n\n\n\n\n\n\n\n\n\n\n\nForm “center ± margin of error”: center is the sample mean; margin uses the t critical value with df = n−1, the sample SD, and √n. Output c(lower, upper).\n\n\n\n\ndata(\"PlantGrowth\")\nxbar &lt;- mean(PlantGrowth$weight); \nsd &lt;- sd(PlantGrowth$weight); \nn &lt;- length(PlantGrowth$weight)\ncritical_value &lt;- qt(0.975, df = n - 1)\nxbar + c(-1,1)*critical_value*sd/sqrt(n)\ndata(\"PlantGrowth\")\nxbar &lt;- mean(PlantGrowth$weight); \nsd &lt;- sd(PlantGrowth$weight); \nn &lt;- length(PlantGrowth$weight)\ncritical_value &lt;- qt(0.975, df = n - 1)\nxbar + c(-1,1)*critical_value*sd/sqrt(n)"
  },
  {
    "objectID": "tutorials/tutorial_04.html#q5-one-sample-ci-for-μ",
    "href": "tutorials/tutorial_04.html#q5-one-sample-ci-for-μ",
    "title": "Tutorial 04: One Sample Confidence Intervals",
    "section": "Q5 — One sample CI for μ",
    "text": "Q5 — One sample CI for μ\nThe dataset used here is river lengths, which gives the lengths (in miles) of 141 “major” rivers in North America, as compiled by the US Geological Survey. Assume river lengths (miles) have known population SD σ = 300. Build a 95% CI for the true mean river length using rivers whe \\(\\alpha = 0.05\\).\n\n\n\nPhoto by kazuend on Unsplash\n\n\n\n\n\n\n\n\nNotePreview\n\n\n\nRun this code chunk to get a glimpse of the dataset. Feel free to change the values to visualize more/less number of rows.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNoteInfo\n\n\n\nWhen σ is unknown, use the t distribution with degrees of freedom n − 1.\n\n\n\n\n\n\n\n\n\n\n\nFind n from the length_miles vector and compute the two-sided 95% z critical value. Then combine it using the formula you have already used in previous questions.\n\n\n\n\nrivers_data &lt;- data.frame(length_miles = as.numeric(datasets::rivers))\nx &lt;- rivers_data$length_miles\nxbar &lt;- mean(x); n &lt;- length(x); z &lt;- qnorm(0.975); sigma &lt;- 300\nxbar + c(-1,1) * z * sigma / sqrt(n)\nrivers_data &lt;- data.frame(length_miles = as.numeric(datasets::rivers))\nx &lt;- rivers_data$length_miles\nxbar &lt;- mean(x); n &lt;- length(x); z &lt;- qnorm(0.975); sigma &lt;- 300\nxbar + c(-1,1) * z * sigma / sqrt(n)"
  },
  {
    "objectID": "tutorials/tutorial_04.html#q6-one-sample-ci-for-μ",
    "href": "tutorials/tutorial_04.html#q6-one-sample-ci-for-μ",
    "title": "Tutorial 04: One Sample Confidence Intervals",
    "section": "Q6 — One-Sample CI for μ",
    "text": "Q6 — One-Sample CI for μ\nUsing airquality$Ozone (ignore missing), construct and print 90% CI for the true mean ozone level (ppb). Assume normality is reasonable.\n\n\n\nPhoto by Tim Witzdam on Unsplash\n\n\n\n\n\n\n\n\nNotePreview\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTwo-sided 90% → \\(t^*\\) at 0.95 with df = n−1; use s for the SD.\n\n\n\n\nw &lt;- na.omit(datasets::airquality$Ozone)\nxbar &lt;- mean(w); s &lt;- sd(w); n &lt;- length(w)\ntstar &lt;- qt(0.95, df = n - 1) # two-sided 90%\nxbar + c(-1,1) * tstar * s / sqrt(n)\nw &lt;- na.omit(datasets::airquality$Ozone)\nxbar &lt;- mean(w); s &lt;- sd(w); n &lt;- length(w)\ntstar &lt;- qt(0.95, df = n - 1) # two-sided 90%\nxbar + c(-1,1) * tstar * s / sqrt(n)"
  },
  {
    "objectID": "tutorials/tutorial_04.html#q7-one-sample-ci-for-a-proportion",
    "href": "tutorials/tutorial_04.html#q7-one-sample-ci-for-a-proportion",
    "title": "Tutorial 04: One Sample Confidence Intervals",
    "section": "Q7 — One-Sample CI for a Proportion",
    "text": "Q7 — One-Sample CI for a Proportion\nIn the UCBAdmissions dataset, Admit status for a student is “Admitted” or “Rejected”. Build and print c(lower, upper) for the 95% CI on the overall admission proportion.\n\n\n\nPhoto by Matt Ragland on Unsplash\n\n\n\n\n\n\n\n\nNoteInfo\n\n\n\nFor a single proportion:\n\\[\n\\mathrm{CI}_{1-\\alpha}:\\ \\hat{p} \\pm z_{1-\\alpha/2}\\,\\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}}.\n\\]\nRule: Ensure \\(n\\hat{p}\\) and \\(n(1 - \\hat{p})\\) are not too small\n\n\n\n\n\n\n\n\nNotePreview\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nphat &lt;- sum(df\\(Freq[df\\)Admit == “Admitted”]) / n and z &lt;- qnorm(0.975) for 95%.\n\n\n\n\ndf &lt;- as.data.frame(datasets::UCBAdmissions)\nn &lt;- sum(df$Freq)\nphat &lt;- sum(df$Freq[df$Admit == \"Admitted\"]) / n\nz &lt;- qnorm(0.975)\nse &lt;- sqrt(phat*(1 - phat)/n)\nphat + c(-1,1) * z * se\ndf &lt;- as.data.frame(datasets::UCBAdmissions)\nn &lt;- sum(df$Freq)\nphat &lt;- sum(df$Freq[df$Admit == \"Admitted\"]) / n\nz &lt;- qnorm(0.975)\nse &lt;- sqrt(phat*(1 - phat)/n)\nphat + c(-1,1) * z * se"
  },
  {
    "objectID": "tutorials/tutorial_04.html#q8---one-sample-ci-for-a-variance-σ²",
    "href": "tutorials/tutorial_04.html#q8---one-sample-ci-for-a-variance-σ²",
    "title": "Tutorial 04: One Sample Confidence Intervals",
    "section": "Q8 - One-Sample CI for a Variance (σ²)",
    "text": "Q8 - One-Sample CI for a Variance (σ²)\nUsing PlantGrowth$weight, print c(lower, upper) for 95% CI on σ^2. (Assume normality.)\n\n\n\n\n\n\nNoteInfo\n\n\n\nFor normal data, the variance CI uses the chi-square distribution with df=n−1:\n\\[\n\\left(\\frac{(n-1)s^2}{\\chi^2_{1-\\alpha/2,\\;n-1}},\\; \\frac{(n-1)s^2}{\\chi^2_{\\alpha/2,\\;n-1}}\\right),\\qquad s^2=\\text{sample variance}.\n\\]\nFor 95%, the cutoffs are at 0.025 and 0.975.\n\n\n\n\n\n\n\n\nNotePreview\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUse \\(s^2\\), df = n−1, and chi-square quantiles at 0.975 and 0.025 (note the order).\n\n\n\n\nx &lt;- datasets::PlantGrowth$weight\nn &lt;- length(x); df &lt;- n - 1; s2 &lt;- var(x)\nchi_lo &lt;- qchisq(0.975, df = df) # upper-tail cutoff\nchi_hi &lt;- qchisq(0.025, df = df) # lower-tail cutoff\nc(df * s2/chi_lo, df*s2/chi_hi)\nx &lt;- datasets::PlantGrowth$weight\nn &lt;- length(x); df &lt;- n - 1; s2 &lt;- var(x)\nchi_lo &lt;- qchisq(0.975, df = df) # upper-tail cutoff\nchi_hi &lt;- qchisq(0.025, df = df) # lower-tail cutoff\nc(df * s2/chi_lo, df*s2/chi_hi)"
  },
  {
    "objectID": "tutorials/tutorial_04.html#q9---one-sample-ci-for-a-proportion-99-practice",
    "href": "tutorials/tutorial_04.html#q9---one-sample-ci-for-a-proportion-99-practice",
    "title": "Tutorial 04: One Sample Confidence Intervals",
    "section": "Q9 - One-Sample CI for a Proportion (99% Practice)",
    "text": "Q9 - One-Sample CI for a Proportion (99% Practice)\nHairEyeColor is a built-in contingency table of Hair × Eye × Gender of Statistics students with counts. Treat each person as a trial and estimate the true proportion with Brown eyes. Construct a 95% Z-interval for the population proportion p. Print c(lower, upper).\n\n\n\n\n\n\n\n\n\n\n\n\n\nNoteInfo\n\n\n\nTwo-sided 1−α CI for a proportion:\n\\[\n\\mathrm{CI}_{1-\\alpha}:\\ \\hat{p} \\pm z_{1-\\alpha/2}\\,\\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}}.\n\\]\nFor 99%, use \\(z^* = \\phi^{-1}\\)(0.995).\n\n\n\n\n\n\n\n\nNotePreview\n\n\n\nHere is a glimpse of the UCBAdmissions dataset.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUse z &lt;- qnorm(0.975) for 95%.\n\n\n\n\ndf &lt;- as.data.frame(datasets::HairEyeColor)\nn &lt;- sum(df$Freq)\nphat &lt;- sum(df$Freq[df$Eye == \"Brown\"]) / n\nz &lt;- qnorm(0.975)\nphat + c(-1,1) * z * sqrt(phat*(1-phat)/n)\ndf &lt;- as.data.frame(datasets::HairEyeColor)\nn &lt;- sum(df$Freq)\nphat &lt;- sum(df$Freq[df$Eye == \"Brown\"]) / n\nz &lt;- qnorm(0.975)\nphat + c(-1,1) * z * sqrt(phat*(1-phat)/n)"
  },
  {
    "objectID": "tutorials/tutorial_11.html#q1---proportion-of-fruity-candies",
    "href": "tutorials/tutorial_11.html#q1---proportion-of-fruity-candies",
    "title": "Tutorial 11: Categorical Data",
    "section": "Q1 - Proportion of fruity candies",
    "text": "Q1 - Proportion of fruity candies\nFor this tutorial, we will be using a Halloween candy dataset that compares different popular candy brands. Calculate the proportion of fruity candies from the dataset.\n\n\n\nPhoto by Joanna Kosinska on Unsplash\n\n\n\n\n\n\n\n\nNoteInfo\n\n\n\nWith categorical datsets like this one, information is usually stored in the form of indicator variables, i.e. value=1 means yes and value=0 means no. For such a 0/1 indicator, the proportion of 1s is mean(indicator == 1).\n\n\n\n\n\n\n\n\nNotePreview\n\n\n\nFeel free to run this code block to visualize the data.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUse the right indicator variable (0 or 1) for fruity candies.\n\n\n\n\n\ndf &lt;- read.csv(\"candy-data.csv\")\nmean(df$fruity == 1)\n\ndf &lt;- read.csv(\"candy-data.csv\")\nmean(df$fruity == 1)"
  },
  {
    "objectID": "tutorials/tutorial_11.html#q2-conditional-proportion",
    "href": "tutorials/tutorial_11.html#q2-conditional-proportion",
    "title": "Tutorial 11: Categorical Data",
    "section": "Q2 — Conditional Proportion",
    "text": "Q2 — Conditional Proportion\nReturn the proportion of hard candies among all fruity candies, i.e. return a single numeric value for P(Hard Candy = 1 | Fruity Candy = 1).\n\n\n\nPhoto by Joanna Kosinska on Unsplash\n\n\n\n\n\n\n\n\nNotePreview\n\n\n\nFeel free to run this code block to visualize the data.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSubset to fruity == 1 and then compute mean(hard == 1) in that subset.\n\n\n\n\ndf &lt;- read.csv(\"candy-data.csv\")\n\nsub &lt;- subset(df, fruity == 1)\nmean(sub$hard == 1)\ndf &lt;- read.csv(\"candy-data.csv\")\n\nsub &lt;- subset(df, fruity == 1)\nmean(sub$hard == 1)"
  },
  {
    "objectID": "tutorials/tutorial_11.html#q3-difference-in-conditional-proportions",
    "href": "tutorials/tutorial_11.html#q3-difference-in-conditional-proportions",
    "title": "Tutorial 11: Categorical Data",
    "section": "Q3 — Difference in Conditional Proportions",
    "text": "Q3 — Difference in Conditional Proportions\nCompute \\(p_1\\) = P(bar == 1 | chocolate == 1), i.e. proportion of candy bars among all chocolate candies and then compute \\(p_0\\) P(bar == 1 | chocolate == 0), i.e. proportion of candy bars among candies that are not made of chocolate. Finally return \\(p_1\\) - \\(p_0\\) .\n\n\n\nPhoto by Denny Müller on Unsplash\n\n\n\n\n\n\n\n\nNotePreview\n\n\n\nFeel free to run this code block to visualize the data.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUse bar as the event and compare chocolate vs. no chocolate.\n\n\n\n\ndf &lt;- read.csv(\"candy-data.csv\")\n\np1 &lt;- mean(subset(df, chocolate == 1)$bar == 1)\np0 &lt;- mean(subset(df, chocolate == 0)$bar == 1)\n\np1 - p0\ndf &lt;- read.csv(\"candy-data.csv\")\n\np1 &lt;- mean(subset(df, chocolate == 1)$bar == 1)\np0 &lt;- mean(subset(df, chocolate == 0)$bar == 1)\n\np1 - p0"
  },
  {
    "objectID": "tutorials/tutorial_11.html#q4-chi-square-test-of-independence",
    "href": "tutorials/tutorial_11.html#q4-chi-square-test-of-independence",
    "title": "Tutorial 11: Categorical Data",
    "section": "Q4 — Chi-square Test of Independence",
    "text": "Q4 — Chi-square Test of Independence\nPerform a chi-sq test of independence between chocolate and bar and return the p-value.\n\n\n\nPhoto by Denny Müller on Unsplash\n\n\n\n\n\n\n\n\nNoteInfo\n\n\n\nA chi-sq test of independence essentially uses a contingency table to test: \\(H_0\\): The variables are independent. vs.  \\(H_a\\): The variables are associated.\nIn R, we can test this by creating a table(x, y) of the two variables and then perform a test on them.\n\n\n\n\n\n\n\n\nNotePreview\n\n\n\nFeel free to run this code block to visualize the data.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMake the appropriate table and fill in the correct test.\n\n\n\n\ndf &lt;- read.csv(\"candy-data.csv\")\n\ntab &lt;- table(df$chocolate, df$bar)\nchisq.test(tab, correct = FALSE)$p.value\ndf &lt;- read.csv(\"candy-data.csv\")\n\ntab &lt;- table(df$chocolate, df$bar)\nchisq.test(tab, correct = FALSE)$p.value"
  },
  {
    "objectID": "tutorials/tutorial_11.html#q5-fishers-exact-test",
    "href": "tutorials/tutorial_11.html#q5-fishers-exact-test",
    "title": "Tutorial 11: Categorical Data",
    "section": "Q5 — Fisher’s Exact Test",
    "text": "Q5 — Fisher’s Exact Test\nRun Fisher’s exact test for association between fruity and hard candies. Return the p-value.\n\n\n\nPhoto by Joanna Kosinska on Unsplash\n\n\n\n\n\n\n\n\nNoteInfo\n\n\n\nFisher’s exact test is often used for 2×2 tables, especially when some expected counts may be small.It’s a non-parametric test, meaning it doesn’t assume data follows a specific distribution, making it more accurate than the Chi-squared test when expected counts are low.\n\n\n\n\n\n\n\n\nNotePreview\n\n\n\nFeel free to run this code block to visualize the data.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMake the appropriate table and fill in the correct test.\n\n\n\n\ndf &lt;- read.csv(\"candy-data.csv\")\n\ntab &lt;- table(df$fruity, df$hard)\nfisher.test(tab)$p.value\ndf &lt;- read.csv(\"candy-data.csv\")\n\ntab &lt;- table(df$fruity, df$hard)\nfisher.test(tab)$p.value"
  },
  {
    "objectID": "tutorials/tutorial_11.html#q6-create-a-categorical-outcome",
    "href": "tutorials/tutorial_11.html#q6-create-a-categorical-outcome",
    "title": "Tutorial 11: Categorical Data",
    "section": "Q6 — Create a Categorical Outcome",
    "text": "Q6 — Create a Categorical Outcome\nData for this dataset was collected from actual people by creating a website where participants were presented with two fun-sized candies and asked to click on the one they would prefer to receive. In total, more than 269 thousand votes were collected from 8,371 different IP addresses.\nHence, each candy has a win percent rate associated with it. For this question:\nCreate high_win as: “High” if winpercent &gt;= median(winpercent)  “Low” otherwise\nThen test whether the proportion of High differs between chocolate and non-chocolate candies using prop.test(…). Return the p-value.\n\n\n\n\n\n\nNoteInfo\n\n\n\nThis is a two-proportion test comparing: \ngroup 1: chocolate = 1 \ngroup 2: chocolate = 0  for the “success” outcome: high_win == “High”\n\n\n\n\n\n\n\n\nNotePreview\n\n\n\nFeel free to run this code block to visualize the data.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFind the cutoff by computing the median and then add in the appropriate indicator variable in the blanks.\n\n\n\n\ndf &lt;- read.csv(\"candy-data.csv\")\n\ncutoff &lt;- median(df$winpercent)\nhigh_win &lt;- ifelse(df$winpercent &gt;= cutoff, \"High\", \"Low\")\n\nx1 &lt;- sum(high_win[df$chocolate == 1] == \"High\")\nn1 &lt;- sum(df$chocolate == 1)\n\nx2 &lt;- sum(high_win[df$chocolate == 0] == \"High\")\nn2 &lt;- sum(df$chocolate == 0)\n\nprop.test(c(x1, x2), c(n1, n2), correct = FALSE)$p.value\ndf &lt;- read.csv(\"candy-data.csv\")\n\ncutoff &lt;- median(df$winpercent)\nhigh_win &lt;- ifelse(df$winpercent &gt;= cutoff, \"High\", \"Low\")\n\nx1 &lt;- sum(high_win[df$chocolate == 1] == \"High\")\nn1 &lt;- sum(df$chocolate == 1)\n\nx2 &lt;- sum(high_win[df$chocolate == 0] == \"High\")\nn2 &lt;- sum(df$chocolate == 0)\n\nprop.test(c(x1, x2), c(n1, n2), correct = FALSE)$p.value"
  },
  {
    "objectID": "tutorials/tutorial_11.html#q7-odds-ratio",
    "href": "tutorials/tutorial_11.html#q7-odds-ratio",
    "title": "Tutorial 11: Categorical Data",
    "section": "Q7 — Odds Ratio",
    "text": "Q7 — Odds Ratio\nCompute the odds ratio for the 2×2 table of chocolate (rows) vs bar (columns)\n\\[\nOR = (a/b) / (c/d)\n\\] where:  - a = #(chocolate=1, bar=1)  - b = #(chocolate=1, bar=0)  - c = #(chocolate=0, bar=1)  - d = #(chocolate=0, bar=0) \n\n\n\nPhoto by Denny Müller on Unsplash\n\n\n\n\n\n\n\n\nNoteInfo\n\n\n\nOdds ratio is a common association measure for 2×2 categorical data:\nOR &gt; 1 suggests positive association \nOR = 1 suggests no association \nOR &lt; 1 suggests negative association \n\n\n\n\n\n\n\n\nNotePreview\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUse the Odd Ratio formula after making the appropriate table.\n\n\n\n\ndf &lt;- read.csv(\"candy-data.csv\")\n\ntab &lt;- table(df$chocolate, df$bar)\n\na &lt;- tab[\"1\",\"1\"]\nb &lt;- tab[\"1\",\"0\"]\nc &lt;- tab[\"0\",\"1\"]\nd &lt;- tab[\"0\",\"0\"]\n\nodds_choc1 &lt;- a / b\nodds_choc0 &lt;- c / d\n\n(or &lt;- odds_choc1 / odds_choc0)\ndf &lt;- read.csv(\"candy-data.csv\")\n\ntab &lt;- table(df$chocolate, df$bar)\n\na &lt;- tab[\"1\",\"1\"]\nb &lt;- tab[\"1\",\"0\"]\nc &lt;- tab[\"0\",\"1\"]\nd &lt;- tab[\"0\",\"0\"]\n\nodds_choc1 &lt;- a / b\nodds_choc0 &lt;- c / d\n\n(or &lt;- odds_choc1 / odds_choc0)"
  },
  {
    "objectID": "tutorials/tutorial_06.html#q1-one-sample-hypothesis-test-on-the-mean-σ-known",
    "href": "tutorials/tutorial_06.html#q1-one-sample-hypothesis-test-on-the-mean-σ-known",
    "title": "Tutorial 06: One Sample Hypothesis Tests",
    "section": "Q1 — One Sample Hypothesis Test on the Mean (σ known)",
    "text": "Q1 — One Sample Hypothesis Test on the Mean (σ known)\nFor this question, we use the 2014 Soccer World Cup Tournament Predictions dataset. Test whether the average Soccer Power Index (spi) for a team equals 70 when the population standard deviation is known to be σ = 12.\nWe test\nH₀: μ = 70\nH₁: μ ≠ 70\nUse a two-sided z-test with σ known.\n\n\n\nPhoto by CamYogi on Unsplash\n\n\n\n\n\n\n\n\nNoteInfo\n\n\n\nThis is a one-sample test on a single numeric variable where the population standard deviation is assumed to be known. In that situation, we use a z-based procedure and compare the sample mean to the hypothesized value.\n\n\n\n\n\n\n\n\nNotePreview\n\n\n\nRun this code chunk to get a glimpse of the dataset. Feel free to change the values to visualize more/less number of rows.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nConfirm you’re comparing the means of two groups formed by a boolean condition on stars. Use the pooled-variance standard error and the appropriate two-sided t critical value for a 95% interval. Print just the lower and upper bounds as a numeric vector.\n\n\n\n\ndf &lt;- read.csv(\"world_cup_predictions.csv\", stringsAsFactors = FALSE, check.names = FALSE)\nspi_col &lt;- df$spi\nmu_0 &lt;- 70\nsigma &lt;- 12\nn &lt;- sum(!is.na(spi_col)) #total number of teams\nxbar &lt;- mean(spi_col, na.rm=TRUE)\nz &lt;- (xbar - mu_0) / (sigma / sqrt(n)) \np_two &lt;- 2 * (1 - pnorm(abs(z)))\n\nc(z = z, p_value = p_two)\ndf &lt;- read.csv(\"world_cup_predictions.csv\", stringsAsFactors = FALSE, check.names = FALSE)\nspi_col &lt;- df$spi\nmu_0 &lt;- 70\nsigma &lt;- 12\nn &lt;- sum(!is.na(spi_col)) #total number of teams\nxbar &lt;- mean(spi_col, na.rm=TRUE)\nz &lt;- (xbar - mu_0) / (sigma / sqrt(n)) \np_two &lt;- 2 * (1 - pnorm(abs(z)))\n\nc(z = z, p_value = p_two)"
  },
  {
    "objectID": "tutorials/tutorial_06.html#q2-one-sample-z-test-on-spi-σ-known-using-bsda",
    "href": "tutorials/tutorial_06.html#q2-one-sample-z-test-on-spi-σ-known-using-bsda",
    "title": "Tutorial 06: One Sample Hypothesis Tests",
    "section": "Q2 — One-sample z-test on SPI (σ known, using BSDA)",
    "text": "Q2 — One-sample z-test on SPI (σ known, using BSDA)\nFor this question, we again use the 2014 Soccer World Cup Tournament Predictions dataset. We want to test whether the average Soccer Power Index (spi) for all teams equals 70 when the population standard deviation is known to be 12. This time we will use the z.test() function from the BSDA package to run the test in a single line, and you will just fill in the key arguments.\n\n\n\n\n\n\nNoteInfo\n\n\n\nBase R does not have a built-in one-sample z-test. The BSDA package provides z.test() which does: compute the z statistic, use the normal distribution, and give the p-value. We are using it here only to shorten the code; the logic is the same as in Q1.\n\n\n\n\n\n\n\n\nNotePreview\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUse the same hypotheses as before (test against 70) and the same known σ (12). Keep the test two-sided.\n\n\n\n\n\ndf &lt;- read.csv(\"world_cup_predictions.csv\")\nx &lt;- df$spi\n\nlibrary(BSDA)\n\nout &lt;- BSDA::z.test(x,\nmu = 70,\nsigma.x = 12,\nalternative = \"two.sided\")\n\nout$p.value\n\ndf &lt;- read.csv(\"world_cup_predictions.csv\")\nx &lt;- df$spi\n\nlibrary(BSDA)\n\nout &lt;- BSDA::z.test(x,\nmu = 70,\nsigma.x = 12,\nalternative = \"two.sided\")\n\nout$p.value"
  },
  {
    "objectID": "tutorials/tutorial_06.html#q3-one-sample-test-on-spi-σ-unknown",
    "href": "tutorials/tutorial_06.html#q3-one-sample-test-on-spi-σ-unknown",
    "title": "Tutorial 06: One Sample Hypothesis Tests",
    "section": "Q3 — One-sample test on SPI (σ unknown)",
    "text": "Q3 — One-sample test on SPI (σ unknown)\nNow test the same hypothesis,\nH₀: μ = 70\nH₁: μ ≠ 70\nbut now do not assume the population standard deviation is known. Use the sample SD, form the t statistic, and get the two-sided p-value from the t distribution.\n\n\n\n\n\n\nNoteInfo\n\n\n\nWhen σ is unknown, we use the sample SD to standardize and compare to a t distribution with n − 1 degrees of freedom.\n\n\n\n\n\n\n\n\nNotePreview\n\n\n\nRun this code chunk to get a glimpse of the dataset. Feel free to change the values to visualize more/less number of rows.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNoteInfo\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUse the SPI column, test against 70, compute mean and sd, then use the t formula and a two-sided p-value from pt().\n\n\n\n\ndf &lt;- read.csv(\"world_cup_predictions.csv\")\nspi_col &lt;- df$spi\n\nmu_0 &lt;- 70\nn &lt;- sum(!is.na(spi_col))\nxbar &lt;- mean(spi_col, na.rm = TRUE)\ns &lt;- sd(spi_col, na.rm = TRUE)\n\ndfree &lt;- n - 1\nt_stat &lt;- (xbar - mu_0) / (s / sqrt(n))\np_two &lt;- 2 * (1 - pt(abs(t_stat), df = dfree))\n\nc(t = t_stat, df = dfree, p_value = p_two)\ndf &lt;- read.csv(\"world_cup_predictions.csv\")\nspi_col &lt;- df$spi\n\nmu_0 &lt;- 70\nn &lt;- sum(!is.na(spi_col))\nxbar &lt;- mean(spi_col, na.rm = TRUE)\ns &lt;- sd(spi_col, na.rm = TRUE)\n\ndfree &lt;- n - 1\nt_stat &lt;- (xbar - mu_0) / (s / sqrt(n))\np_two &lt;- 2 * (1 - pt(abs(t_stat), df = dfree))\n\nc(t = t_stat, df = dfree, p_value = p_two)"
  },
  {
    "objectID": "tutorials/tutorial_06.html#q4-one-sample-t-test-on-spi-σ-unknown-built-in",
    "href": "tutorials/tutorial_06.html#q4-one-sample-t-test-on-spi-σ-unknown-built-in",
    "title": "Tutorial 06: One Sample Hypothesis Tests",
    "section": "Q4 — One-sample t-test on SPI (σ unknown, built-in)",
    "text": "Q4 — One-sample t-test on SPI (σ unknown, built-in)\nFor this question, we again use the 2014 Soccer World Cup Tournament Predictions dataset. We want to test whether the average Soccer Power Index (spi) for all teams equals 70, but we will let R do the one-sample t-test for us using the built-in t.test() function. This is the “practical” version of Q3.\n\n\n\n\n\n\nNoteInfo\n\n\n\nWhen the population standard deviation is not given, we use a one-sample t-test: t.test(x, mu = μ₀, alternative = “two.sided”) R will estimate the standard deviation, use df = n − 1, and return the p-value.\n\n\n\n\n\n\n\n\n\n\n\nUse the SPI column from the data, test it against 70, and keep the test two-sided.\n\n\n\n\n\ndf &lt;- read.csv(\"world_cup_predictions.csv\")\nx &lt;- df$spi\nout &lt;- t.test(x, mu = 70, alternative = \"two.sided\")\nout$p.value\n\ndf &lt;- read.csv(\"world_cup_predictions.csv\")\nx &lt;- df$spi\nout &lt;- t.test(x, mu = 70, alternative = \"two.sided\")\nout$p.value"
  },
  {
    "objectID": "tutorials/tutorial_06.html#q5-one-sample-t-test-on-track-score-σ-unknown-manual-large-n",
    "href": "tutorials/tutorial_06.html#q5-one-sample-t-test-on-track-score-σ-unknown-manual-large-n",
    "title": "Tutorial 06: One Sample Hypothesis Tests",
    "section": "Q5 — One-sample t-test on Track Score (σ unknown, manual, large n)",
    "text": "Q5 — One-sample t-test on Track Score (σ unknown, manual, large n)\nFor this question, use the large music dataset. We want to test whether the average track score in this dataset equals 45.\nH₀: μ = 45 H₁: μ ≠ 45\nWe will compute the test statistic and the p-value manually.\n\n\n\n\n\n\nNoteInfo\n\n\n\nOne-sample t (σ unknown):\n\\(t=\\frac{\\bar{x} - \\mu_0}{s/\\sqrt{n}}\\), with df = n-1, and two-sided p-value \\(p = 2 \\times(1 - F_t(|t|)).\\)\n\n\n\n\n\n\n\n\nNotePreview\n\n\n\nRun this code chunk to get a glimpse of the dataset. Feel free to change the values to visualize more/less number of rows.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUse Track.Score as x, use mean() and sd() before plugging into the t formula. Make it two-sided.\n\n\n\n\n\ndf &lt;- read.csv(\"spotify-2024.csv\")\nx &lt;- df$Track.Score\nx &lt;- x[is.finite(x)]\n\nmu_0 &lt;- 45\nn &lt;- length(x)\nxbar &lt;- mean(x)\ns &lt;- sd(x)\n\ndfree &lt;- n - 1\nt_stat &lt;- (xbar - mu_0) / (s / sqrt(n))\np_two &lt;- 2 * (1 - pt(abs(t_stat), df = dfree))\n\nc(t = t_stat, df = dfree, p_value = p_two)\n\ndf &lt;- read.csv(\"spotify-2024.csv\")\nx &lt;- df$Track.Score\nx &lt;- x[is.finite(x)]\n\nmu_0 &lt;- 45\nn &lt;- length(x)\nxbar &lt;- mean(x)\ns &lt;- sd(x)\n\ndfree &lt;- n - 1\nt_stat &lt;- (xbar - mu_0) / (s / sqrt(n))\np_two &lt;- 2 * (1 - pt(abs(t_stat), df = dfree))\n\nc(t = t_stat, df = dfree, p_value = p_two)"
  },
  {
    "objectID": "tutorials/tutorial_06.html#q6-one-sample-t-test-on-track-score-σ-unknown-built-in",
    "href": "tutorials/tutorial_06.html#q6-one-sample-t-test-on-track-score-σ-unknown-built-in",
    "title": "Tutorial 06: One Sample Hypothesis Tests",
    "section": "Q6 — One-sample t-test on Track Score (σ unknown, built-in)",
    "text": "Q6 — One-sample t-test on Track Score (σ unknown, built-in)\nNow run the same hypothesis test using R’s built-in t.test() on the same column.\nH₀: μ = 45 H₁: μ ≠ 45\n\n\n\n\n\n\nNoteInfo\n\n\n\nt.test(x, mu = 45, alternative = “two.sided”) will estimate the SD, use df = n − 1, and give the p-value.\n\n\n\n\n\n\n\n\nNotePreview\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUse the Track.Score column.\n\n\n\n\n\ndf &lt;- read.csv(\"spotify-2024.csv\")\nx &lt;- df$Track.Score\n\nout &lt;- t.test(x,\nmu = 45,\nalternative = \"two.sided\")\n\nout$p.value\n\ndf &lt;- read.csv(\"spotify-2024.csv\")\nx &lt;- df$Track.Score\n\nout &lt;- t.test(x,\nmu = 45,\nalternative = \"two.sided\")\n\nout$p.value"
  },
  {
    "objectID": "tutorials/tutorial_06.html#q7-one-sample-test-on-a-proportion-base-r-prop.test",
    "href": "tutorials/tutorial_06.html#q7-one-sample-test-on-a-proportion-base-r-prop.test",
    "title": "Tutorial 06: One Sample Hypothesis Tests",
    "section": "Q7 — One-sample test on a proportion (base R prop.test())",
    "text": "Q7 — One-sample test on a proportion (base R prop.test())\nWe use the video game sales dataset. Let’s test whether 30% of the listed games were published by Nintendo.\nHypotheses:\n\\((H_0: p = 0.045)\\) \\((H_1: p \\neq 0.045)\\)\nWe will form a success/failure variable: “Publisher is Nintendo” = success.\n\n\n\n\n\n\nNoteInfo\n\n\n\nFor a one-sample test on a proportion with counts (x) out of (n), use prop.test(x, n, p = p0, alternative = \"two.sided\"). This uses a chi-square test with 1 degree of freedom.\n\n\n\n\n\n\n\n\nNotePreview\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCount how many rows have Publisher == “Nintendo”, test against 0.045, and keep it two-sided.\n\n\n\n\n\nvg &lt;- read.csv(\"vgsales.csv\")\n\nx &lt;- sum(vg$Publisher == \"Nintendo\", na.rm = TRUE)\nn &lt;- sum(!is.na(vg$Publisher))\n\nout &lt;- prop.test(x = x,\n                 n = n,\n                 p = 0.045,\n                 alternative = \"two.sided\")\n\nout$p.value\n\nvg &lt;- read.csv(\"vgsales.csv\")\n\nx &lt;- sum(vg$Publisher == \"Nintendo\", na.rm = TRUE)\nn &lt;- sum(!is.na(vg$Publisher))\n\nout &lt;- prop.test(x = x,\n                 n = n,\n                 p = 0.045,\n                 alternative = \"two.sided\")\n\nout$p.value"
  },
  {
    "objectID": "tutorials/tutorial_06.html#q8-from-chi-square-to-z-follow-up-on-the-same-test",
    "href": "tutorials/tutorial_06.html#q8-from-chi-square-to-z-follow-up-on-the-same-test",
    "title": "Tutorial 06: One Sample Hypothesis Tests",
    "section": "Q8 — From chi-square to z (follow-up on the same test)",
    "text": "Q8 — From chi-square to z (follow-up on the same test)\nprop.test() reports a chi-square statistic with 1 df. For a 1-df test, (^2 = z^2). Let’s extract that chi-square value and take the square root.\nWe use the same dataset and the same hypothesis as Q7.\n\n\n\n\n\n\nNoteInfo\n\n\n\nIf a one-sample proportion test gives (^2) with 1 df, then ( z = ) (keep the sign if you need direction).\n\n\n\n\n\n\n\n\n\n\n\nRe-run the same prop.test() as Q7 and take sqrt() of the test statistic.\n\n\n\n\n\nvg &lt;- read.csv(\"vgsales.csv\")\n\nx &lt;- sum(vg$Publisher == \"Nintendo\", na.rm = TRUE)\nn &lt;- sum(!is.na(vg$Publisher))\n\nout &lt;- prop.test(x = x,\n                 n = n,\n                 p = 0.045,\n                 alternative = \"two.sided\")\n\nchisq_val &lt;- out$statistic\nz_val &lt;- sqrt(chisq_val)\n\nc(chisq = chisq_val, z_from_chisq = z_val)\n\nvg &lt;- read.csv(\"vgsales.csv\")\n\nx &lt;- sum(vg$Publisher == \"Nintendo\", na.rm = TRUE)\nn &lt;- sum(!is.na(vg$Publisher))\n\nout &lt;- prop.test(x = x,\n                 n = n,\n                 p = 0.045,\n                 alternative = \"two.sided\")\n\nchisq_val &lt;- out$statistic\nz_val &lt;- sqrt(chisq_val)\n\nc(chisq = chisq_val, z_from_chisq = z_val)"
  },
  {
    "objectID": "tutorials/tutorial_06.html#q9-one-sample-proportion-using-prop_test-rstatix",
    "href": "tutorials/tutorial_06.html#q9-one-sample-proportion-using-prop_test-rstatix",
    "title": "Tutorial 06: One Sample Hypothesis Tests",
    "section": "Q9 — One-sample proportion using prop_test() (rstatix)",
    "text": "Q9 — One-sample proportion using prop_test() (rstatix)\nNow we repeat the same test — “is the proportion of Nintendo-published games 30%?” — but use the prop_test() function from the rstatix package, which gives the z statistic directly.\nWe’ll create a logical column and then test it.\n\n\n\n\n\n\nNoteInfo\n\n\n\nrstatix::prop_test() can test a single proportion vs a hypothesized value and returns a z statistic and p-value. We’ll test against 0.045.\n\n\n\n\n\n\n\n\n\n\n\nUse the logical column is_nintendo.\n\n\n\n\nlibrary(rstatix)\n\nvg &lt;- read.csv(\"vgsales.csv\")\n\nvg$is_nintendo &lt;- vg$Publisher == \"Nintendo\"\n\nout &lt;- rstatix::prop_test(\n  x = sum(vg$is_nintendo, na.rm = TRUE),\n  n = sum(!is.na(vg$is_nintendo)),\n  p = 0.045\n)\n\nout\nlibrary(rstatix)\n\nvg &lt;- read.csv(\"vgsales.csv\")\n\nvg$is_nintendo &lt;- vg$Publisher == \"Nintendo\"\n\nout &lt;- rstatix::prop_test(\n  x = sum(vg$is_nintendo, na.rm = TRUE),\n  n = sum(!is.na(vg$is_nintendo)),\n  p = 0.045\n)\n\nout"
  },
  {
    "objectID": "tutorials/tutorial_08.html#q1-one-way-anova-manual-happiness-score-by-region",
    "href": "tutorials/tutorial_08.html#q1-one-way-anova-manual-happiness-score-by-region",
    "title": "Tutorial 08: ANOVA",
    "section": "Q1 — One-way ANOVA (manual): Happiness score by region",
    "text": "Q1 — One-way ANOVA (manual): Happiness score by region\nWe start this tutorial with the city lifestyle dataset, that gives info about In the city lifestyle dataset, we want to test whether the mean happiness score differs across four regions: Europe, Asia, North America, and Africa.\nWe test:\n\\[\nH_0: \\mu_{\\text{Europe}} = \\mu_{\\text{Asia}} = \\mu_{\\text{NorthAm}} = \\mu_{\\text{Africa}}\n\\]\nvs\n\\[\nH_1:\\ \\text{at least one regional mean is different.}\n\\]\nUse a one-way ANOVA on happiness score, computed manually from sums of squares.\nYour task:\n\nSubset to those four regions.\n\nRemove rows with missing happiness scores.\n\nCompute SSR, SSE, \\(df1\\), \\(df2\\), MSR, MSE, F, and the p-value\n\n\\[\nF = \\frac{\\text{MSR}}{\\text{MSE}}, \\qquad\np = P\\bigl(F_{df1, df2} \\ge F\\bigr).\n\\]\nReturn a named numeric vector: c(F = Fstat, df1 = df1, df2 = df2, p_value = pval).\n\n\n\nPhoto by Arno Retief on Unsplash\n\n\n\n\n\n\n\n\nNoteInfo\n\n\n\nFor a one-way ANOVA with response \\(y_{ij}\\) in group (i) (of size \\(n_i\\)), group means \\(bar{y}_i\\), and overall mean \\(bar{y}\\):\nBetween–group sum of squares \\[\n\\mathrm{SSR} = \\sum_i n_i \\, (\\hat{y}_i - \\bar{y})^2\n\\]\nWithin–group sum of squares \\[\n\\mathrm{SSE} = \\sum_i (y_{i} - \\hat{y_{i}})^2\n\\]\nDegrees of freedom \\[\ndf_{\\text{between}} = k - 1, \\qquad\ndf_{\\text{within}} = N - k\n\\]\nMean squares \\[\n\\mathrm{MSR} = \\frac{\\mathrm{SSB}}{df_{\\text{between}}}, \\qquad\n\\mathrm{MSE} = \\frac{\\mathrm{SSW}}{df_{\\text{within}}}\n\\]\n\n\n\n\n\n\n\n\nNotePreview\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUse mean for both group and overall means. df1 = k - 1, df2 = N - k. MSR = SSB / df1, MSE = SSW / df2, then Fstat = MSR / MSE.\n\n\n\n\n\ndf &lt;- read.csv(\"city_lifestyle_dataset.csv\")\n\nsub &lt;- subset(\ndf,\ncountry %in% c(\"Europe\",\"Asia\",\"North America\",\"Africa\")\n& is.finite(happiness_score)\n)\n\nsub$region &lt;- factor(sub$country)\n\ny &lt;- sub$happiness_score\ng &lt;- sub$region\n\ngroup_means &lt;- tapply(y, g, mean)\ngroup_ns    &lt;- tapply(y, g, length)\n\noverall_mean &lt;- mean(y)\n\nSSB &lt;- sum(group_ns * (group_means - overall_mean)^2)\n\nSSW &lt;- sum(tapply(y, g, function(x) sum((x - mean(x))^2)))\n\nk  &lt;- length(group_means)\nN  &lt;- length(y)\n\ndf1 &lt;- k - 1\ndf2  &lt;- N - k\n\nMSR &lt;- SSB / df1\nMSE &lt;- SSW / df2\n\nFstat &lt;- MSR / MSE\npval  &lt;- pf(Fstat, df1, df2, lower.tail = FALSE)\n\nc(F = Fstat, df1 = df1, df2 = df2, p_value = pval)\n\ndf &lt;- read.csv(\"city_lifestyle_dataset.csv\")\n\nsub &lt;- subset(\ndf,\ncountry %in% c(\"Europe\",\"Asia\",\"North America\",\"Africa\")\n& is.finite(happiness_score)\n)\n\nsub$region &lt;- factor(sub$country)\n\ny &lt;- sub$happiness_score\ng &lt;- sub$region\n\ngroup_means &lt;- tapply(y, g, mean)\ngroup_ns    &lt;- tapply(y, g, length)\n\noverall_mean &lt;- mean(y)\n\nSSB &lt;- sum(group_ns * (group_means - overall_mean)^2)\n\nSSW &lt;- sum(tapply(y, g, function(x) sum((x - mean(x))^2)))\n\nk  &lt;- length(group_means)\nN  &lt;- length(y)\n\ndf1 &lt;- k - 1\ndf2  &lt;- N - k\n\nMSR &lt;- SSB / df1\nMSE &lt;- SSW / df2\n\nFstat &lt;- MSR / MSE\npval  &lt;- pf(Fstat, df1, df2, lower.tail = FALSE)\n\nc(F = Fstat, df1 = df1, df2 = df2, p_value = pval)"
  },
  {
    "objectID": "tutorials/tutorial_08.html#q2-one-way-anova-built-in-happiness-score-by-region",
    "href": "tutorials/tutorial_08.html#q2-one-way-anova-built-in-happiness-score-by-region",
    "title": "Tutorial 08: ANOVA",
    "section": "Q2 — One-way ANOVA (built-in): Happiness score by region",
    "text": "Q2 — One-way ANOVA (built-in): Happiness score by region\nNow we will redo the same test using R’s built-in aov() function on the same subset of the city dataset.\nReturn c(F = Fstat, df1 = df_region, df2 = df_resid, p_value = p) extracted from the ANOVA table.\n\n\n\n\n\n\nNoteInfo\n\n\n\nFor a one-way ANOVA fit with fit &lt;- aov(y ~ group, data = …), you can extract the ANOVA table with summary(fit)[[1]]. The row corresponding to the factor has columns:\n“Df”: factor degrees of freedom\n“F value”: F statistic\n“Pr(&gt;F)”: p-value\n\n\n\n\n\n\n\n\nNotePreview\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUse happiness_score ~ region in aov(), and “region” as the row name in the ANOVA table.\n\n\n\n\n\ndf &lt;- read.csv(\"city_lifestyle_dataset.csv\")\n\nsub &lt;- subset(\ndf,\ncountry %in% c(\"Europe\",\"Asia\",\"North America\",\"Africa\")\n& is.finite(happiness_score)\n)\n\nsub$region &lt;- factor(sub$country)\n\nfit &lt;- aov(happiness_score ~ region, data = sub)\n\ntab &lt;- summary(fit)[[1]]\n\ndf_region &lt;- tab[\"region\", \"Df\"]\ndf_resid  &lt;- tab[\"Residuals\", \"Df\"]\nFstat     &lt;- tab[\"region\", \"F value\"]\npval      &lt;- tab[\"region\", \"Pr(&gt;F)\"]\n\nc(F = Fstat, df1 = df_region, df2 = df_resid, p_value = pval)\n\ndf &lt;- read.csv(\"city_lifestyle_dataset.csv\")\n\nsub &lt;- subset(\ndf,\ncountry %in% c(\"Europe\",\"Asia\",\"North America\",\"Africa\")\n& is.finite(happiness_score)\n)\n\nsub$region &lt;- factor(sub$country)\n\nfit &lt;- aov(happiness_score ~ region, data = sub)\n\ntab &lt;- summary(fit)[[1]]\n\ndf_region &lt;- tab[\"region\", \"Df\"]\ndf_resid  &lt;- tab[\"Residuals\", \"Df\"]\nFstat     &lt;- tab[\"region\", \"F value\"]\npval      &lt;- tab[\"region\", \"Pr(&gt;F)\"]\n\nc(F = Fstat, df1 = df_region, df2 = df_resid, p_value = pval)"
  },
  {
    "objectID": "tutorials/tutorial_08.html#q3-fishers-lsd-no-adjustment-pairwise-region-comparisons",
    "href": "tutorials/tutorial_08.html#q3-fishers-lsd-no-adjustment-pairwise-region-comparisons",
    "title": "Tutorial 08: ANOVA",
    "section": "Q3 — Fisher’s LSD (no adjustment): Pairwise region comparisons",
    "text": "Q3 — Fisher’s LSD (no adjustment): Pairwise region comparisons\nUsing the same city subset as in Q1–Q2, perform pairwise t-tests on happiness scores between regions without multiple-comparison adjustment. This corresponds to Fisher’s LSD after a significant global ANOVA.\nUse pairwise.t.test() with p.adjust.method = “none” and return the matrix of p-values.\n\n\n\n\n\n\nNoteInfo\n\n\n\nFisher’s LSD (Least Significant Difference) is essentially:\nRun a global ANOVA to check that at least one mean differs.\nIf significant, run unadjusted pairwise t-tests between groups, using the same residual variance.\nIn R, pairwise.t.test(y, group, p.adjust.method = “none”)$p.value gives a matrix of unadjusted pairwise p-values.\n\n\n\n\n\n\n\n\nNotePreview\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUse sub$happiness_score as the response, sub$region as the group, and “none” for p.adjust.method.\n\n\n\n\n\ndf &lt;- read.csv(\"city_lifestyle_dataset.csv\")\n\nsub &lt;- subset(\ndf,\ncountry %in% c(\"Europe\",\"Asia\",\"North America\",\"Africa\")\n& is.finite(happiness_score)\n)\n\nsub$region &lt;- factor(sub$country)\n\nout &lt;- pairwise.t.test(sub$happiness_score,\nsub$region,\np.adjust.method = \"none\")\n\nout$p.value\n\ndf &lt;- read.csv(\"city_lifestyle_dataset.csv\")\n\nsub &lt;- subset(\ndf,\ncountry %in% c(\"Europe\",\"Asia\",\"North America\",\"Africa\")\n& is.finite(happiness_score)\n)\n\nsub$region &lt;- factor(sub$country)\n\nout &lt;- pairwise.t.test(sub$happiness_score,\nsub$region,\np.adjust.method = \"none\")\n\nout$p.value"
  },
  {
    "objectID": "tutorials/tutorial_08.html#q4-bonferroni-adjusted-pairwise-region-comparisons",
    "href": "tutorials/tutorial_08.html#q4-bonferroni-adjusted-pairwise-region-comparisons",
    "title": "Tutorial 08: ANOVA",
    "section": "Q4 — Bonferroni-adjusted pairwise region comparisons",
    "text": "Q4 — Bonferroni-adjusted pairwise region comparisons\nNow repeat the previous question but use a Bonferroni correction for multiple comparisons. Again, return the matrix of p-values.\n\n\n\n\n\n\nNoteInfo\n\n\n\nThe Bonferroni adjustment is a simple and conservative way to control the family-wise error rate when making many comparisons. In R, use p.adjust.method = “bonferroni” in pairwise.t.test().\n\n\n\n\n\n\n\n\nNotePreview\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUse the same sub$happiness_score and sub$region, but set p.adjust.method = “bonferroni”.\n\n\n\n\n\ndf &lt;- read.csv(\"city_lifestyle_dataset.csv\")\n\nsub &lt;- subset(\ndf,\ncountry %in% c(\"Europe\",\"Asia\",\"North America\",\"Africa\")\n& is.finite(happiness_score)\n)\n\nsub$region &lt;- factor(sub$country)\n\nout &lt;- pairwise.t.test(sub$happiness_score,\nsub$region,\np.adjust.method = \"bonferroni\")\n\nout$p.value\n\ndf &lt;- read.csv(\"city_lifestyle_dataset.csv\")\n\nsub &lt;- subset(\ndf,\ncountry %in% c(\"Europe\",\"Asia\",\"North America\",\"Africa\")\n& is.finite(happiness_score)\n)\n\nsub$region &lt;- factor(sub$country)\n\nout &lt;- pairwise.t.test(sub$happiness_score,\nsub$region,\np.adjust.method = \"bonferroni\")\n\nout$p.value"
  },
  {
    "objectID": "tutorials/tutorial_08.html#q5-one-way-anova-manual-exam-score-by-motivation-level",
    "href": "tutorials/tutorial_08.html#q5-one-way-anova-manual-exam-score-by-motivation-level",
    "title": "Tutorial 08: ANOVA",
    "section": "Q5 — One-way ANOVA (manual): Exam score by motivation level",
    "text": "Q5 — One-way ANOVA (manual): Exam score by motivation level\nIn the student performance dataset, we want to test whether the mean exam score differs across motivation levels (Low, Medium, High).\nWe test\n\\[\nH_0:\\ \\mu_{\\text{Low}} = \\mu_{\\text{Medium}} = \\mu_{\\text{High}}\n\\]\nvs\n\\[\nH_1:\\ \\text{at least one of } \\mu_{\\text{Low}},\\, \\mu_{\\text{Medium}},\\, \\mu_{\\text{High}} \\text{ is different.}\n\\]\nUse a one-way ANOVA on Exam_Score, computed manually from sums of squares.\nYour task:\n\nSubset to rows with non-missing Exam_Score and Motivation_Level.\n\nTreat Motivation_Level as a factor with three levels (Low, Medium, High).\n\nCompute SSR, SSE, df1, df2, MSR, MSE, (F), and the p-value\n\n\\[\nF = \\frac{\\mathrm{MSR}}{\\mathrm{MSE}}, \\qquad\np = P\\bigl(F_{df_1, df_2} \\ge F\\bigr).\n\\]\nReturn a named numeric vector:\nc(F = Fstat, df1 = df1, df2 = df2, p_value = pval).\n\n\n\nPhoto by Leonardo Vargas on Unsplash\n\n\n\n\n\n\n\n\nNotePreview\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSame pattern as Q1: use mean for group and overall means. df1 = k - 1, df2 = N - k, MSR = SSR/df1, MSE = SSE/df2.\n\n\n\n\n\ndf &lt;- read.csv(\"student_performance.csv\")\n\nsub &lt;- subset(df,\n!is.na(Exam_Score) &\n!is.na(Motivation_Level))\n\nsub$mot &lt;- factor(sub$Motivation_Level)\n\ny &lt;- sub$Exam_Score\ng &lt;- sub$mot\n\ngroup_means &lt;- tapply(y, g, mean)\ngroup_ns    &lt;- tapply(y, g, length)\n\noverall_mean &lt;- mean(y)\n\nSSB &lt;- sum(group_ns * (group_means - overall_mean)^2)\n\nSSW &lt;- sum(tapply(y, g, function(x) sum((x - mean(x))^2)))\n\nk  &lt;- length(group_means)\nN  &lt;- length(y)\n\ndf1 &lt;- k - 1\ndf2  &lt;- N - k\n\nMSR &lt;- SSB / df1\nMSE &lt;- SSW / df2\n\nFstat &lt;- MSR / MSE\npval  &lt;- pf(Fstat, df1, df2, lower.tail = FALSE)\n\nc(F = Fstat, df1 = df1, df2 = df2, p_value = pval)\n\ndf &lt;- read.csv(\"student_performance.csv\")\n\nsub &lt;- subset(df,\n!is.na(Exam_Score) &\n!is.na(Motivation_Level))\n\nsub$mot &lt;- factor(sub$Motivation_Level)\n\ny &lt;- sub$Exam_Score\ng &lt;- sub$mot\n\ngroup_means &lt;- tapply(y, g, mean)\ngroup_ns    &lt;- tapply(y, g, length)\n\noverall_mean &lt;- mean(y)\n\nSSB &lt;- sum(group_ns * (group_means - overall_mean)^2)\n\nSSW &lt;- sum(tapply(y, g, function(x) sum((x - mean(x))^2)))\n\nk  &lt;- length(group_means)\nN  &lt;- length(y)\n\ndf1 &lt;- k - 1\ndf2  &lt;- N - k\n\nMSR &lt;- SSB / df1\nMSE &lt;- SSW / df2\n\nFstat &lt;- MSR / MSE\npval  &lt;- pf(Fstat, df1, df2, lower.tail = FALSE)\n\nc(F = Fstat, df1 = df1, df2 = df2, p_value = pval)"
  },
  {
    "objectID": "tutorials/tutorial_08.html#q6-one-way-anova-built-in-exam-score-by-motivation-level",
    "href": "tutorials/tutorial_08.html#q6-one-way-anova-built-in-exam-score-by-motivation-level",
    "title": "Tutorial 08: ANOVA",
    "section": "Q6 — One-way ANOVA (built-in): Exam score by motivation level",
    "text": "Q6 — One-way ANOVA (built-in): Exam score by motivation level\nNow use aov() to test for differences in mean exam score across motivation levels.\nReturn c(F = Fstat, df1 = df_mot, df2 = df_resid, p_value = pval).\n\n\n\n\n\n\nNotePreview\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUse Exam_Score ~ mot, and the row name “mot” in the ANOVA table.\n\n\n\n\n\ndf &lt;- read.csv(\"student_performance.csv\")\n\nsub &lt;- subset(df,\n!is.na(Exam_Score) &\n!is.na(Motivation_Level))\n\nsub$mot &lt;- factor(sub$Motivation_Level)\n\nfit &lt;- aov(Exam_Score ~ mot, data = sub)\n\ntab &lt;- summary(fit)[[1]]\n\ndf_mot   &lt;- tab[\"mot\", \"Df\"]\ndf_resid &lt;- tab[\"Residuals\", \"Df\"]\nFstat    &lt;- tab[\"mot\", \"F value\"]\npval     &lt;- tab[\"mot\", \"Pr(&gt;F)\"]\n\nc(F = Fstat, df1 = df_mot, df2 = df_resid, p_value = pval)\n\ndf &lt;- read.csv(\"student_performance.csv\")\n\nsub &lt;- subset(df,\n!is.na(Exam_Score) &\n!is.na(Motivation_Level))\n\nsub$mot &lt;- factor(sub$Motivation_Level)\n\nfit &lt;- aov(Exam_Score ~ mot, data = sub)\n\ntab &lt;- summary(fit)[[1]]\n\ndf_mot   &lt;- tab[\"mot\", \"Df\"]\ndf_resid &lt;- tab[\"Residuals\", \"Df\"]\nFstat    &lt;- tab[\"mot\", \"F value\"]\npval     &lt;- tab[\"mot\", \"Pr(&gt;F)\"]\n\nc(F = Fstat, df1 = df_mot, df2 = df_resid, p_value = pval)"
  },
  {
    "objectID": "tutorials/tutorial_08.html#q7-fishers-lsd-exam-score-pairwise-comparisons-by-motivation",
    "href": "tutorials/tutorial_08.html#q7-fishers-lsd-exam-score-pairwise-comparisons-by-motivation",
    "title": "Tutorial 08: ANOVA",
    "section": "Q7 — Fisher’s LSD: Exam score pairwise comparisons by motivation",
    "text": "Q7 — Fisher’s LSD: Exam score pairwise comparisons by motivation\nUsing the same subset as Q5–Q6, compute unadjusted pairwise t-tests on Exam_Score across motivation levels (Fisher’s LSD).\nReturn the matrix of p-values.\n\n\n\n\n\n\nNotePreview\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUse sub$Exam_Score, sub$mot, and “none” as the adjustment method.\n\n\n\n\n\ndf &lt;- read.csv(\"student_performance.csv\")\n\nsub &lt;- subset(df,\n!is.na(Exam_Score) &\n!is.na(Motivation_Level))\n\nsub$mot &lt;- factor(sub$Motivation_Level)\n\nout &lt;- pairwise.t.test(sub$Exam_Score,\nsub$mot,\np.adjust.method = \"none\")\n\nout$p.value\n\ndf &lt;- read.csv(\"student_performance.csv\")\n\nsub &lt;- subset(df,\n!is.na(Exam_Score) &\n!is.na(Motivation_Level))\n\nsub$mot &lt;- factor(sub$Motivation_Level)\n\nout &lt;- pairwise.t.test(sub$Exam_Score,\nsub$mot,\np.adjust.method = \"none\")\n\nout$p.value"
  },
  {
    "objectID": "tutorials/tutorial_08.html#q8-bonferroni-exam-score-pairwise-comparisons-by-parental-education",
    "href": "tutorials/tutorial_08.html#q8-bonferroni-exam-score-pairwise-comparisons-by-parental-education",
    "title": "Tutorial 08: ANOVA",
    "section": "Q8 — Bonferroni: Exam score pairwise comparisons by parental education",
    "text": "Q8 — Bonferroni: Exam score pairwise comparisons by parental education\nFinally, investigate another factor: parental education level (High School, College, Postgraduate).\nUse the student dataset to:\nSubset to rows with non-missing Exam_Score and Parental_Education_Level.\nTreat Parental_Education_Level as a factor with three levels.\nRun pairwise.t.test() on Exam_Score across parental education levels, using Bonferroni adjustment.\nReturn the p-value matrix.\n\n\n\n\n\n\nNotePreview\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUse sub$Exam_Score and sub$edu with p.adjust.method = “bonferroni”.\n\n\n\n\n\ndf &lt;- read.csv(\"student_performance.csv\")\n\nsub &lt;- subset(df,\n!is.na(Exam_Score) &\n!is.na(Parental_Education_Level))\n\nsub$edu &lt;- factor(sub$Parental_Education_Level)\n\nout &lt;- pairwise.t.test(sub$Exam_Score,\nsub$edu,\np.adjust.method = \"bonferroni\")\n\nout$p.value\n\ndf &lt;- read.csv(\"student_performance.csv\")\n\nsub &lt;- subset(df,\n!is.na(Exam_Score) &\n!is.na(Parental_Education_Level))\n\nsub$edu &lt;- factor(sub$Parental_Education_Level)\n\nout &lt;- pairwise.t.test(sub$Exam_Score,\nsub$edu,\np.adjust.method = \"bonferroni\")\n\nout$p.value"
  },
  {
    "objectID": "tutorials/tut1.html",
    "href": "tutorials/tut1.html",
    "title": "WebR-enabled code cell",
    "section": "",
    "text": "This is a webr-enabled code cell in a Quarto HTML document.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "tutorials/tut1.html#demo",
    "href": "tutorials/tut1.html#demo",
    "title": "WebR-enabled code cell",
    "section": "",
    "text": "This is a webr-enabled code cell in a Quarto HTML document.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "STA258: Statistics with Applied Probability\n\nTutorials",
    "section": "",
    "text": "Welcome to STA258 tutorials!\n\n\nAbout the course:  STA258 discusses a survey of statistical methodology with emphasis on the relationship between data analysis and probability theory. Topics covered include descriptive statistics, limit theorems, sampling distribution, point and interval estimation, hypothesis testing, contingency tables and count data, simple linear regression.\n\n\nAuthors: \nAarushi Alreja  Kabir Bhatia  Nishan Mudalige"
  },
  {
    "objectID": "tutorials/tutorial_09.html#q1-fit-a-simple-linear-regression-model-movies-only",
    "href": "tutorials/tutorial_09.html#q1-fit-a-simple-linear-regression-model-movies-only",
    "title": "Tutorial 09: Intro to Regression",
    "section": "Q1 — Fit a simple linear regression model (movies only)",
    "text": "Q1 — Fit a simple linear regression model (movies only)\nUsing titles.csv, we will work with movies only and fit:\n\\[y = \\beta_0 + \\beta_1 x + \\varepsilon\\] keeping y = imdb_score and x = runtime.\nYour task:  - Fit a regression line  - Return a named numeric vector: c(b0 = ..., b1 = ...)\n\n\n\nPhoto by Thibault Penin on Unsplash\n\n\n\n\n\n\n\n\nNoteInfo\n\n\n\nA simple linear regression estimates a straight-line relationship between a predictor x and a response y.\n\n\\(b_0\\) (intercept): the predicted value of y when x = 0\n\\(b_1\\) (slope): the predicted change in y for a one-unit increase in x\n\nIn R, once you fit the model, you can extract the two estimated coefficients from the fitted object.\n\n\n\n\n\n\n\n\nNotePreview\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nYou need a fitted regression model object using the filtered movie data. Then extract the two coefficient estimates from that object (intercept first, slope second).\n\n\n\n\n\ndf &lt;- read.csv(\"titles.csv\")\n\nsub &lt;- subset(df,\ntype == \"MOVIE\" &\nis.finite(runtime) &\nis.finite(imdb_score) &\nruntime &gt; 0\n)\n\nfit &lt;- lm(imdb_score ~ runtime, data = sub)\n\nb &lt;- coef(fit)\nc(b0 = unname(b[1]), b1 = unname(b[2]))\n\ndf &lt;- read.csv(\"titles.csv\")\n\nsub &lt;- subset(df,\ntype == \"MOVIE\" &\nis.finite(runtime) &\nis.finite(imdb_score) &\nruntime &gt; 0\n)\n\nfit &lt;- lm(imdb_score ~ runtime, data = sub)\n\nb &lt;- coef(fit)\nc(b0 = unname(b[1]), b1 = unname(b[2]))"
  },
  {
    "objectID": "tutorials/tutorial_09.html#q2-compute-hatbeta_1-slope-by-computation",
    "href": "tutorials/tutorial_09.html#q2-compute-hatbeta_1-slope-by-computation",
    "title": "Tutorial 09: Intro to Regression",
    "section": "Q2 — Compute (\\(\\hat\\beta_1\\)) (slope) by computation",
    "text": "Q2 — Compute (\\(\\hat\\beta_1\\)) (slope) by computation\nCompute the slope estimator using the formula:\n\\[\\hat\\beta_1=\\frac{\\sum (x_i-\\bar x)(y_i-\\bar y)}{\\sum (x_i-\\bar x)^2}\\]\nHere, (x=runtime) and (y=imdb_score) (movies only). Return the numeric value b1_hat.\n\n\n\n\n\n\nNoteInfo\n\n\n\nLet:\n\nThe numerator measures how x and y move together (a “covariance-like” quantity).\nThe denominator measures how spread out x is (a “variance-like” quantity).\nThe slope is the “co-movement” scaled by the spread in x.\n\n\n\n\n\n\n\n\n\nNotePreview\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nStart by centering both variables around their sample means. Then compute the two sums shown in the formula (top and bottom) and combine them to get the slope.\n\n\n\n\n\ndf &lt;- read.csv(\"titles.csv\")\n\nsub &lt;- subset(df,\ntype == \"MOVIE\" &\nis.finite(runtime) &\nis.finite(imdb_score) &\nruntime &gt; 0\n)\n\nx &lt;- sub$runtime\ny &lt;- sub$imdb_score\n\nxbar &lt;- mean(x)\nybar &lt;- mean(y)\n\nnum &lt;- sum((x - xbar) * (y - ybar))\nden &lt;- sum((x - xbar)^2)\n\nb1_hat &lt;- num / den\nb1_hat\n\ndf &lt;- read.csv(\"titles.csv\")\n\nsub &lt;- subset(df,\ntype == \"MOVIE\" &\nis.finite(runtime) &\nis.finite(imdb_score) &\nruntime &gt; 0\n)\n\nx &lt;- sub$runtime\ny &lt;- sub$imdb_score\n\nxbar &lt;- mean(x)\nybar &lt;- mean(y)\n\nnum &lt;- sum((x - xbar) * (y - ybar))\nden &lt;- sum((x - xbar)^2)\n\nb1_hat &lt;- num / den\nb1_hat"
  },
  {
    "objectID": "tutorials/tutorial_09.html#q3-compute-hatbeta_0-intercept-by-computation",
    "href": "tutorials/tutorial_09.html#q3-compute-hatbeta_0-intercept-by-computation",
    "title": "Tutorial 09: Intro to Regression",
    "section": "Q3 — Compute (\\(\\hat\\beta_0\\)) (intercept) by computation",
    "text": "Q3 — Compute (\\(\\hat\\beta_0\\)) (intercept) by computation\nCompute the intercept estimator:\n\\[\n\\hat\\beta_0 = \\bar y - \\hat\\beta_1 \\bar x\n\\]\nReturn the numeric value \\(\\hat{\\beta_0}\\).\n\n\n\n\n\n\nNoteInfo\n\n\n\nConceptually:\n\nThe fitted regression line must pass through the point (\\(\\bar{x}, \\bar{y}\\)).\nOnce you have the slope, the intercept is whatever value makes the line go through that mean point.\n\n\n\n\n\n\n\n\n\nNotePreview\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUse the fact that the fitted line goes through (\\(\\bar{x}, \\bar{y}\\)). If you already computed the slope in Q2, you only need sample means to determine the intercept.\n\n\n\n\n\ndf &lt;- read.csv(\"titles.csv\")\n\nsub &lt;- subset(df,\ntype == \"MOVIE\" &\nis.finite(runtime) &\nis.finite(imdb_score) &\nruntime &gt; 0\n)\n\nx &lt;- sub$runtime\ny &lt;- sub$imdb_score\n\nxbar &lt;- mean(x)\nybar &lt;- mean(y)\n\nb1_hat &lt;- sum((x - xbar) * (y - ybar)) / sum((x - xbar)^2)\n\nb0_hat &lt;- ybar - b1_hat * xbar\nb0_hat\n\ndf &lt;- read.csv(\"titles.csv\")\n\nsub &lt;- subset(df,\ntype == \"MOVIE\" &\nis.finite(runtime) &\nis.finite(imdb_score) &\nruntime &gt; 0\n)\n\nx &lt;- sub$runtime\ny &lt;- sub$imdb_score\n\nxbar &lt;- mean(x)\nybar &lt;- mean(y)\n\nb1_hat &lt;- sum((x - xbar) * (y - ybar)) / sum((x - xbar)^2)\n\nb0_hat &lt;- ybar - b1_hat * xbar\nb0_hat"
  },
  {
    "objectID": "tutorials/tutorial_09.html#q4-cross-check-hatbeta_0-hatbeta_1-using-summarylm",
    "href": "tutorials/tutorial_09.html#q4-cross-check-hatbeta_0-hatbeta_1-using-summarylm",
    "title": "Tutorial 09: Intro to Regression",
    "section": "Q4 — Cross-check ( \\(\\hat\\beta_0\\), \\(\\hat\\beta_1\\)) using summary(lm)",
    "text": "Q4 — Cross-check ( \\(\\hat\\beta_0\\), \\(\\hat\\beta_1\\)) using summary(lm)\nFit the same model as Q1 and extract coefficients from:\nsummary(fit)$coefficients\nReturn c(b0 = ..., b1 = ...).\n\n\n\n\n\n\nNoteInfo\n\n\n\nMost regression summaries include a coefficient table where:\n\neach row corresponds to a coefficient (intercept + predictor)\nthe main estimate column gives the fitted coefficient values\n\nYour goal is to extract the two estimates for this model.\n\n\n\n\n\n\n\n\nNotePreview\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLook for the coefficient table in the model summary. It will have a row for the intercept and a row for the predictor, and an “estimate”-type column containing the fitted values.\n\n\n\n\n\ndf &lt;- read.csv(\"titles.csv\")\n\nsub &lt;- subset(df,\ntype == \"MOVIE\" &\nis.finite(runtime) &\nis.finite(imdb_score) &\nruntime &gt; 0\n)\n\nfit &lt;- lm(imdb_score ~ runtime, data = sub)\n\ntab &lt;- summary(fit)$coefficients\n\nb0 &lt;- tab[\"(Intercept)\", \"Estimate\"]\nb1 &lt;- tab[\"runtime\", \"Estimate\"]\n\nc(b0 = b0, b1 = b1)\n\ndf &lt;- read.csv(\"titles.csv\")\n\nsub &lt;- subset(df,\ntype == \"MOVIE\" &\nis.finite(runtime) &\nis.finite(imdb_score) &\nruntime &gt; 0\n)\n\nfit &lt;- lm(imdb_score ~ runtime, data = sub)\n\ntab &lt;- summary(fit)$coefficients\n\nb0 &lt;- tab[\"(Intercept)\", \"Estimate\"]\nb1 &lt;- tab[\"runtime\", \"Estimate\"]\n\nc(b0 = b0, b1 = b1)"
  },
  {
    "objectID": "tutorials/tutorial_09.html#q5-point-prediction-by-hand-using-b0-b1",
    "href": "tutorials/tutorial_09.html#q5-point-prediction-by-hand-using-b0-b1",
    "title": "Tutorial 09: Intro to Regression",
    "section": "Q5 — Point prediction by hand (using b0, b1)",
    "text": "Q5 — Point prediction by hand (using b0, b1)\nUsing the same filtered movie subset and the fitted line, compute the predicted IMDB score when:\n\n\\(x_0 = 90\\) minutes\n\nReturn a single numeric value: yhat_90.\n\n\n\n\n\n\nNoteInfo\n\n\n\nA point prediction on a fitted line is the model’s estimated mean response at a chosen \\(x_0\\). Conceptually: “plug in \\(x_0\\) into the fitted line.”\n\n\n\n\n\n\n\n\nNotePreview\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA point prediction uses the fitted line’s two coefficients and a chosen (x_0). Use the intercept + slope idea (one part is the “baseline”, the other is the “change per minute” times (x_0)).\n\n\n\n\n\ndf &lt;- read.csv(\"titles.csv\")\n\nsub &lt;- subset(df,\ntype == \"MOVIE\" &\nis.finite(runtime) &\nis.finite(imdb_score) &\nruntime &gt; 0\n)\n\nfit &lt;- lm(imdb_score ~ runtime, data = sub)\nb &lt;- coef(fit)\n\nx0 &lt;- 90\nyhat_90 &lt;- b[1] + b[2] * x0\nyhat_90\n\ndf &lt;- read.csv(\"titles.csv\")\n\nsub &lt;- subset(df,\ntype == \"MOVIE\" &\nis.finite(runtime) &\nis.finite(imdb_score) &\nruntime &gt; 0\n)\n\nfit &lt;- lm(imdb_score ~ runtime, data = sub)\nb &lt;- coef(fit)\n\nx0 &lt;- 90\nyhat_90 &lt;- b[1] + b[2] * x0\nyhat_90"
  },
  {
    "objectID": "tutorials/tutorial_09.html#q6-point-prediction-using-predict",
    "href": "tutorials/tutorial_09.html#q6-point-prediction-using-predict",
    "title": "Tutorial 09: Intro to Regression",
    "section": "Q6 — Point prediction using predict()",
    "text": "Q6 — Point prediction using predict()\nUse the fitted model to predict the IMDB score at:\n\n\\((x_0 = 90)\\) minutes\n\nThis time, use predict() and a newdata data frame.\nReturn a single numeric value: yhat_90.\n\n\n\n\n\n\nNoteInfo\n\n\n\nBuilt-in prediction methods require:\n\na fitted model object\na newdata data frame with the predictor column named exactly as in the model\n\n\n\n\n\n\n\n\n\nNotePreview\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCreate a one-row newdata data frame whose column name matches the predictor used in the model, then call the model’s prediction function and extract the numeric value.\n\n\n\n\n\ndf &lt;- read.csv(\"titles.csv\")\n\nsub &lt;- subset(df,\ntype == \"MOVIE\" &\nis.finite(runtime) &\nis.finite(imdb_score) &\nruntime &gt; 0\n)\n\nfit &lt;- lm(imdb_score ~ runtime, data = sub)\n\nnew &lt;- data.frame(runtime = 90)\nyhat_90 &lt;- predict(fit, newdata = new)\nyhat_90\n\ndf &lt;- read.csv(\"titles.csv\")\n\nsub &lt;- subset(df,\ntype == \"MOVIE\" &\nis.finite(runtime) &\nis.finite(imdb_score) &\nruntime &gt; 0\n)\n\nfit &lt;- lm(imdb_score ~ runtime, data = sub)\n\nnew &lt;- data.frame(runtime = 90)\nyhat_90 &lt;- predict(fit, newdata = new)\nyhat_90"
  },
  {
    "objectID": "tutorials/tutorial_09.html#q7-compare-two-predictions-difference-in-fitted-values",
    "href": "tutorials/tutorial_09.html#q7-compare-two-predictions-difference-in-fitted-values",
    "title": "Tutorial 09: Intro to Regression",
    "section": "Q7 — Compare two predictions (difference in fitted values)",
    "text": "Q7 — Compare two predictions (difference in fitted values)\nUsing the fitted model, compute:\n\\[\\hat{y}(120) - \\hat y(80)\\]\nReturn a single numeric value: diff_hat.\n\n\n\n\n\n\nNoteInfo\n\n\n\nThis question is about comparing fitted values at two predictor values. Conceptually: “how much does the model expect the response to change when (x) changes from 80 to 120?”\n\n\n\n\n\n\n\n\nNotePreview\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGet two fitted values for (x=80) and (x=120) (any reasonable method), then subtract in the requested order.\n\n\n\n\n\ndf &lt;- read.csv(\"titles.csv\")\n\nsub &lt;- subset(df,\ntype == \"MOVIE\" &\nis.finite(runtime) &\nis.finite(imdb_score) &\nruntime &gt; 0\n)\n\nfit &lt;- lm(imdb_score ~ runtime, data = sub)\n\nyhat &lt;- predict(fit, newdata = data.frame(runtime = c(80, 120)))\ndiff_hat &lt;- yhat[2] - yhat[1]\ndiff_hat\n\ndf &lt;- read.csv(\"titles.csv\")\n\nsub &lt;- subset(df,\ntype == \"MOVIE\" &\nis.finite(runtime) &\nis.finite(imdb_score) &\nruntime &gt; 0\n)\n\nfit &lt;- lm(imdb_score ~ runtime, data = sub)\n\nyhat &lt;- predict(fit, newdata = data.frame(runtime = c(80, 120)))\ndiff_hat &lt;- yhat[2] - yhat[1]\ndiff_hat"
  },
  {
    "objectID": "tutorials/index.html",
    "href": "tutorials/index.html",
    "title": "STA258 Course Tutorials",
    "section": "",
    "text": "Welcome !"
  },
  {
    "objectID": "tutorials/tutorial_07.html#q1-pooled-two-sample-t-test-audience-score-avengers-vs-spider-man",
    "href": "tutorials/tutorial_07.html#q1-pooled-two-sample-t-test-audience-score-avengers-vs-spider-man",
    "title": "Tutorial 07: Two Sample Hypothesis Tests",
    "section": "Q1 — Pooled two-sample t-test (Audience score: Avengers vs Spider-Man)",
    "text": "Q1 — Pooled two-sample t-test (Audience score: Avengers vs Spider-Man)\nFor this question, we use marvel.csv. Compare the audience % score between Avengers and Spider-Man movies.\nWe test \\[ H_0 : \\mu_{Avengers} - \\mu_{Spider-Man} = 0\\] vs \\[H_1 : \\mu_{Avengers} - \\mu_{Spider-Man} \\neq 0\\]\nassuming equal population variances and using a pooled two-sample t-test. Compute the p-value manually from the sample statistics and the t distribution. Your final output should be a single numeric p-value.\n\n\n\nPhoto by Erik Mclean on Unsplash\n\n\n\n\n\n\n\n\nNoteInfo\n\n\n\nIn a pooled two-sample t-test for two groups with sample sizes (n_1, n_2), sample means (x_1, x_2), and sample standard deviations (s_1, s_2), we first compute the pooled variance\n\\[\ns_p^2 = \\frac{(n_1 - 1)s_1^2 + (n_2 - 1)s_2^2}{n_1 + n_2 - 2}.\n\\]\nThe test statistic for testing (H_0: _1 - _2 = 0) is\n\\[\nt = \\frac{\\bar x_1 - \\bar x_2}{\\sqrt{s_p^2\\left(\\frac{1}{n_1} + \\frac{1}{n_2}\\right)}}.\n\\]\nUnder the null hypothesis, this statistic follows a t distribution with\n\\[\n\\text{df} = n_1 + n_2 - 2\n\\]\ndegrees of freedom. For a two-sided test, the p-value is\n\\[\np\\text{-value} = 2\\,P\\bigl(T_{\\text{df}} \\ge |t|\\bigr).\n\\]\n\n\n\n\n\n\n\n\nNotePreview\n\n\n\nRun this code chunk to get a glimpse of the dataset and visualize the audience scores.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSeparate the audience scores for each franchise, then use their sample sizes, means, and standard deviations to construct the pooled variance, the standardized test statistic, and the two-sided p-value from the appropriate t distribution.\n\n\n\n\n\ndf &lt;- read.csv(\"marvel.csv\", check.names = FALSE)\n\ndf &lt;- subset(df, category %in% c(\"Avengers\",\"Spider-Man\"))\ndf$aud &lt;- suppressWarnings(as.numeric(sub(\"%\", \"\", df[[\"audience % score\"]], fixed = TRUE)))\ndf &lt;- subset(df, is.finite(aud))\n\ng1 &lt;- df$aud[df$category == \"Avengers\"]\ng2 &lt;- df$aud[df$category == \"Spider-Man\"]\n\nn1 &lt;- length(g1); n2 &lt;- length(g2)\nm1 &lt;- mean(g1);   m2 &lt;- mean(g2)\ns1 &lt;- sd(g1);     s2 &lt;- sd(g2)\n\nsp2  &lt;- ((n1-1)*s1^2 + (n2-1)*s2^2)/(n1+n2-2)\ntval &lt;- (m1-m2)/sqrt(sp2*(1/n1 + 1/n2))\ndf_t &lt;- n1+n2-2\npval &lt;- 2*pt(-abs(tval), df_t)\npval\n\ndf &lt;- read.csv(\"marvel.csv\", check.names = FALSE)\n\ndf &lt;- subset(df, category %in% c(\"Avengers\",\"Spider-Man\"))\ndf$aud &lt;- suppressWarnings(as.numeric(sub(\"%\", \"\", df[[\"audience % score\"]], fixed = TRUE)))\ndf &lt;- subset(df, is.finite(aud))\n\ng1 &lt;- df$aud[df$category == \"Avengers\"]\ng2 &lt;- df$aud[df$category == \"Spider-Man\"]\n\nn1 &lt;- length(g1); n2 &lt;- length(g2)\nm1 &lt;- mean(g1);   m2 &lt;- mean(g2)\ns1 &lt;- sd(g1);     s2 &lt;- sd(g2)\n\nsp2  &lt;- ((n1-1)*s1^2 + (n2-1)*s2^2)/(n1+n2-2)\ntval &lt;- (m1-m2)/sqrt(sp2*(1/n1 + 1/n2))\ndf_t &lt;- n1+n2-2\npval &lt;- 2*pt(-abs(tval), df_t)\npval"
  },
  {
    "objectID": "tutorials/tutorial_07.html#q2-welch-two-sample-t-test-opening-weekend-avengers-vs-spider-man",
    "href": "tutorials/tutorial_07.html#q2-welch-two-sample-t-test-opening-weekend-avengers-vs-spider-man",
    "title": "Tutorial 07: Two Sample Hypothesis Tests",
    "section": "Q2 — Welch two-sample t-test (Opening weekend: Avengers vs Spider-Man)",
    "text": "Q2 — Welch two-sample t-test (Opening weekend: Avengers vs Spider-Man)\nNow use marvel.csv to compare the opening weekend gross (in $m) between Avengers and Spider-Man movies.\nWe test \\[ H_0 : \\mu_{Avengers} - \\mu_{Spider-Man} = 0\\] vs \\[H_1 : \\mu_{Avengers} - \\mu_{Spider-Man} \\neq 0\\]\nwithout assuming equal variances. Use the Welch two-sample t-test formula and compute the p-value manually from the t distribution. Do not call the built-in t.test function in this question. Return a single numeric p-value.\n\n\n\nPhoto by Erik Mclean on Unsplash\n\n\n\n\n\n\n\n\nNoteInfo\n\n\n\nIn the Welch two-sample t-test, we keep the sample variances separate. For two groups with sample sizes (n_1, n_2), means (x_1, x_2), and standard deviations (s_1, s_2), the test statistic is\n\\[\nt = \\frac{\\bar x_1 - \\bar x_2}{\\sqrt{\\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2}}}.\n\\]\nThe approximate Welch degrees of freedom are\n\\[\n\\text{df}_W =\n\\frac{\\left(\\dfrac{s_1^2}{n_1} + \\dfrac{s_2^2}{n_2}\\right)^2}{\n\\dfrac{\\left(\\dfrac{s_1^2}{n_1}\\right)^2}{n_1 - 1}\n+\n\\dfrac{\\left(\\dfrac{s_2^2}{n_2}\\right)^2}{n_2 - 1}\n}.\n\\]\nFor a two-sided test of (H_0: _1 - _2 = 0), the p-value is\n\\[\np\\text{-value} = 2\\,P\\bigl(T_{\\text{df}_W} \\ge |t|\\bigr).\n\\]\n\n\n\n\n\n\n\n\nNotePreview\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSeparate the opening weekend values by franchise, compute the sample means and variances, standardize the difference using the Welch standard error, then use the Welch degrees-of-freedom formula and a two-sided t distribution to obtain the p-value.\n\n\n\n\n\ndf &lt;- read.csv(\"marvel.csv\", check.names = FALSE)\ndf &lt;- subset(df, category %in% c(\"Avengers\",\"Spider-Man\"))\ndf$open &lt;- df[[\"opening weekend ($m)\"]]\ndf &lt;- df[is.finite(df$open), ]\n\ng1 &lt;- df$open[df$category == \"Avengers\"]\ng2 &lt;- df$open[df$category == \"Spider-Man\"]\n\nn1 &lt;- length(g1); n2 &lt;- length(g2)\nm1 &lt;- mean(g1);   m2 &lt;- mean(g2)\ns1 &lt;- sd(g1);     s2 &lt;- sd(g2)\n\nse_diff &lt;- sqrt(s1^2 / n1 + s2^2 / n2)\ntval &lt;- (m1 - m2) / se_diff\n\ndf_w &lt;- (s1^2 / n1 + s2^2 / n2)^2 /\n  ((s1^2 / n1)^2 / (n1 - 1) + (s2^2 / n2)^2 / (n2 - 1))\n\npval &lt;- 2 * pt(-abs(tval), df_w)\npval\n\ndf &lt;- read.csv(\"marvel.csv\", check.names = FALSE)\ndf &lt;- subset(df, category %in% c(\"Avengers\",\"Spider-Man\"))\ndf$open &lt;- df[[\"opening weekend ($m)\"]]\ndf &lt;- df[is.finite(df$open), ]\n\ng1 &lt;- df$open[df$category == \"Avengers\"]\ng2 &lt;- df$open[df$category == \"Spider-Man\"]\n\nn1 &lt;- length(g1); n2 &lt;- length(g2)\nm1 &lt;- mean(g1);   m2 &lt;- mean(g2)\ns1 &lt;- sd(g1);     s2 &lt;- sd(g2)\n\nse_diff &lt;- sqrt(s1^2 / n1 + s2^2 / n2)\ntval &lt;- (m1 - m2) / se_diff\n\ndf_w &lt;- (s1^2 / n1 + s2^2 / n2)^2 /\n  ((s1^2 / n1)^2 / (n1 - 1) + (s2^2 / n2)^2 / (n2 - 1))\n\npval &lt;- 2 * pt(-abs(tval), df_w)\npval"
  },
  {
    "objectID": "tutorials/tutorial_07.html#q3-pooled-two-sample-t-test-critics-score-captain-america-vs-iron-man",
    "href": "tutorials/tutorial_07.html#q3-pooled-two-sample-t-test-critics-score-captain-america-vs-iron-man",
    "title": "Tutorial 07: Two Sample Hypothesis Tests",
    "section": "Q3 — Pooled two-sample t-test (Critics score: Captain America vs Iron Man)",
    "text": "Q3 — Pooled two-sample t-test (Critics score: Captain America vs Iron Man)\nNow compare critics % score between Captain America and Iron Man movies in marvel.csv.\nWe test \\[ H_0 : \\mu_{Cap} - \\mu_{Iron Man} = 0\\] vs \\[H_1 : \\mu_{Cap} - \\mu_{Iron Man} \\neq 0\\]\nand we treat the population variances as equal, using a pooled two-sample t-test. Your answer should be a single numeric p-value.\n\n\n\nPhoto by Mateusz Wacławek on Unsplash\n\n\n\n\n\n\n\n\nNoteInfo\n\n\n\nThis is another two-sample mean comparison where we assume the two sets of critics scores arise from populations with the same variance. Under that assumption, we combine the information from both groups into one pooled estimate of the variance to build the test statistic.\n\n\n\n\n\n\n\n\nNotePreview\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLimit the data to the two franchises named in the question, use the critics scores as the response, and form a two-level grouping factor. Then carry out a pooled two-sample test and extract the single p-value it produces.\n\n\n\n\ndf &lt;- read.csv(\"marvel.csv\", check.names = FALSE)\ndf &lt;- subset(df, category %in% c(\"Captain America\",\"Iron Man\"))\n\ndf$crit &lt;- suppressWarnings(as.numeric(sub(\"%\",\"\", df[[\"critics % score\"]], fixed = TRUE)))\ndf &lt;- subset(df, is.finite(crit))\n\ndf$grp &lt;- factor(df$category, levels = c(\"Captain America\",\"Iron Man\"))\nt.test(crit ~ grp, data = df, var.equal = TRUE)$p.value\ndf &lt;- read.csv(\"marvel.csv\", check.names = FALSE)\ndf &lt;- subset(df, category %in% c(\"Captain America\",\"Iron Man\"))\n\ndf$crit &lt;- suppressWarnings(as.numeric(sub(\"%\",\"\", df[[\"critics % score\"]], fixed = TRUE)))\ndf &lt;- subset(df, is.finite(crit))\n\ndf$grp &lt;- factor(df$category, levels = c(\"Captain America\",\"Iron Man\"))\nt.test(crit ~ grp, data = df, var.equal = TRUE)$p.value"
  },
  {
    "objectID": "tutorials/tutorial_07.html#q4-welch-two-sample-t-test-domestic-gross-black-panther-vs-thor",
    "href": "tutorials/tutorial_07.html#q4-welch-two-sample-t-test-domestic-gross-black-panther-vs-thor",
    "title": "Tutorial 07: Two Sample Hypothesis Tests",
    "section": "Q4 — Welch two-sample t-test (Domestic gross: Black Panther vs Thor)",
    "text": "Q4 — Welch two-sample t-test (Domestic gross: Black Panther vs Thor)\nFinally, compare the domestic gross (in $m) between Black Panther movies and Thor movies in marvel.csv.\nWe test \\[ H_0 : \\mu_{Black Panther} - \\mu_{Thor} = 0\\] vs \\[H_1 : \\mu_{Black Panther} - \\mu_{Thor} \\neq 0\\]\nHere we do not assume the variances are equal and instead use a Welch two-sample t-test. Your answer should be a single numeric p-value.\n\n\n\nPhoto by Mateusz Wacławek on Unsplash\n\n\n\n\n\n\n\n\nNoteInfo\n\n\n\nThis is another two-sample test where the two groups may have quite different variability. The Welch approach adjusts both the test statistic and degrees of freedom to account for unequal variances.\n\n\n\n\n\n\n\n\nNotePreview\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWork only with the two franchises specified, treat domestic gross as the numeric response, and compare the two groups while allowing their variances to differ. Extract just the p-value from the resulting test object.\n\n\n\n\ndf &lt;- read.csv(\"marvel.csv\", check.names = FALSE)\ndf &lt;- subset(df, category %in% c(\"Black Panther\",\"Thor\"))\n\ndf$dom &lt;- suppressWarnings(as.numeric(df[[\"domestic gross ($m)\"]]))\ndf &lt;- df[is.finite(df$dom), ]\n\ndf$grp &lt;- factor(df$category, levels = c(\"Black Panther\",\"Thor\"))\n\npval &lt;- t.test(dom ~ grp, data = df, var.equal = FALSE)$p.value\nunname(as.numeric(pval))\ndf &lt;- read.csv(\"marvel.csv\", check.names = FALSE)\ndf &lt;- subset(df, category %in% c(\"Black Panther\",\"Thor\"))\n\ndf$dom &lt;- suppressWarnings(as.numeric(df[[\"domestic gross ($m)\"]]))\ndf &lt;- df[is.finite(df$dom), ]\n\ndf$grp &lt;- factor(df$category, levels = c(\"Black Panther\",\"Thor\"))\n\npval &lt;- t.test(dom ~ grp, data = df, var.equal = FALSE)$p.value\nunname(as.numeric(pval))"
  },
  {
    "objectID": "tutorials/tutorial_07.html#q5-welch-two-sample-t-test-using-built-in-method-hp-legendary-vs-non-legendary",
    "href": "tutorials/tutorial_07.html#q5-welch-two-sample-t-test-using-built-in-method-hp-legendary-vs-non-legendary",
    "title": "Tutorial 07: Two Sample Hypothesis Tests",
    "section": "Q5 — Welch two-sample t-test using built-in method (HP: Legendary vs non-Legendary)",
    "text": "Q5 — Welch two-sample t-test using built-in method (HP: Legendary vs non-Legendary)\nUse Pokemon.csv to test whether the proportion of Legendary Pokémon is the same in Generation 1 and Generation 2.\nLet “success” be Legendary = TRUE. Define:\n\nGroup 1: Generation 1\n\nGroup 2: Generation 2\n\nWe test\n\\[\nH_0:\\ p_1 - p_2 = 0\n\\]\nversus\n\\[\nH_1:\\ p_1 - p_2 \\neq 0,\n\\]\nwhere (p_1) and (p_2) are the true proportions of Legendary Pokémon in Generation 1 and 2.\nCompute the p-value manually using the normal approximation formulas. Your final output must be a single numeric p-value.\n\n\n\nPhoto by Thimo Pedersen on Unsplash\n\n\n\n\n\n\n\n\nNoteInfo\n\n\n\nLet (x_1, x_2) be the number of successes in groups 1 and 2, and (n_1, n_2) the corresponding sample sizes. The sample proportions are\n\\[\n\\hat{p}_1 = \\frac{x_1}{n_1},\n\\qquad\n\\hat{p}_2 = \\frac{x_2}{n_2}.\n\\]\nUnder (H_0: p_1 = p_2), the pooled proportion is\n\\[\n\\hat{p} = \\frac{x_1 + x_2}{n_1 + n_2}.\n\\]\nThe standard error for the difference in proportions under the null is\n\\[\n\\text{SE}(\\hat{p}_1 - \\hat{p}_2)\n=\n\\sqrt{\n\\hat{p}(1 - \\hat{p})\\left(\\frac{1}{n_1} + \\frac{1}{n_2}\\right)\n}.\n\\]\nThe test statistic ::: {.callout-note title=“Preview”}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nForm a two-level factor for Legendary status, use HP as the response in a two-sample procedure that allows unequal variances, and then pull out the single p-value component from the test result.\n\n\n\n\ndf &lt;- read.csv(\"Pokemon.csv\")\ndf$Legendary &lt;- df$Legendary == \"True\"\ndf$grp &lt;- factor(df$Legendary, levels = c(FALSE, TRUE))\nres &lt;- t.test(HP ~ grp, data = df, var.equal = FALSE)\nres$p.value\ndf &lt;- read.csv(\"Pokemon.csv\")\ndf$Legendary &lt;- df$Legendary == \"True\"\ndf$grp &lt;- factor(df$Legendary, levels = c(FALSE, TRUE))\nres &lt;- t.test(HP ~ grp, data = df, var.equal = FALSE)\nres$p.value"
  },
  {
    "objectID": "tutorials/tutorial_07.html#q6-two-sample-test-for-difference-of-proportions-using-built-in-method",
    "href": "tutorials/tutorial_07.html#q6-two-sample-test-for-difference-of-proportions-using-built-in-method",
    "title": "Tutorial 07: Two Sample Hypothesis Tests",
    "section": "Q6 — Two-sample test for difference of proportions using built-in method",
    "text": "Q6 — Two-sample test for difference of proportions using built-in method\nAgain compare the proportion of Legendary Pokémon in Generation 1 and Generation 2, but now using a built-in two-sample proportion test.\nLet “success” be Legendary = TRUE.\nWe test\n\\[\nH_0:\\ p_1 - p_2 = 0\n\\]\nversus\n\\[\nH_1:\\ p_1 - p_2 \\neq 0,\n\\]\nwhere (p_1) and (p_2) are the true proportions of Legendary Pokémon in Generation 1 and Generation 2.\nUse a built-in two-sample test for proportions and return a single numeric p-value.\n\n\n\nPhoto by Thimo Pedersen on Unsplash\n\n\n\n\n\n\n\n\nNoteInfo\n\n\n\nA built-in two-sample test for proportions needs: - the vector of successes in each group, ((x_1, x_2))\n- the vector of sample sizes, ((n_1, n_2))\nIt then constructs the appropriate test statistic and p-value under the null hypothesis that the two population proportions are equal.\n\n\n\n\n\n\n\n\nNotePreview\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCount the Legendary Pokémon and total Pokémon in Generations 1 and 2, pass those counts and sample sizes to a two-sample proportion test, and extract the p-value from the result.\n\n\n\n\ndf &lt;- read.csv(\"Pokemon.csv\")\ndf$Legendary &lt;- df$Legendary == \"True\"\ndf &lt;- subset(df, Generation %in% c(1, 2))\n\nx1 &lt;- sum(df$Legendary[df$Generation == 1])\nx2 &lt;- sum(df$Legendary[df$Generation == 2])\n\nn1 &lt;- sum(df$Generation == 1)\nn2 &lt;- sum(df$Generation == 2)\n\nres &lt;- suppressWarnings(prop.test(c(x1, x2), c(n1, n2), correct = TRUE))\nres$p.value\ndf &lt;- read.csv(\"Pokemon.csv\")\ndf$Legendary &lt;- df$Legendary == \"True\"\ndf &lt;- subset(df, Generation %in% c(1, 2))\n\nx1 &lt;- sum(df$Legendary[df$Generation == 1])\nx2 &lt;- sum(df$Legendary[df$Generation == 2])\n\nn1 &lt;- sum(df$Generation == 1)\nn2 &lt;- sum(df$Generation == 2)\n\nres &lt;- suppressWarnings(prop.test(c(x1, x2), c(n1, n2), correct = TRUE))\nres$p.value"
  },
  {
    "objectID": "tutorials/tutorial_07.html#q7-f-test-for-ratio-of-variances-using-built-in-method-attack-fire-vs-water",
    "href": "tutorials/tutorial_07.html#q7-f-test-for-ratio-of-variances-using-built-in-method-attack-fire-vs-water",
    "title": "Tutorial 07: Two Sample Hypothesis Tests",
    "section": "Q7 — F-test for ratio of variances using built-in method (Attack: Fire vs Water)",
    "text": "Q7 — F-test for ratio of variances using built-in method (Attack: Fire vs Water)\nUse Pokemon.csv to compare the variance of Attack between Fire-type and Water-type Pokémon (using the primary type Type 1).\nLet\n\nGroup 1: Type 1 = Fire\n\nGroup 2: Type 1 = Water\n\nWe test\n\\[\nH_0:\\ \\sigma_{\\text{Fire}}^2 = \\sigma_{\\text{Water}}^2\n\\]\nversus\n\\[\nH_1:\\ \\sigma_{\\text{Fire}}^2 \\neq \\sigma_{\\text{Water}}^2.\n\\]\nUse an appropriate built-in two-sample test for equality of variances and return a single numeric p-value.\n\n\n\nPhoto by Life Time Values on Unsplash\n\n\n\n\n\n\n\n\nNoteInfo\n\n\n\nA built-in two-sample variance test compares the sample variances of two groups using an F statistic and the F distribution. It uses the group sample sizes to set the numerator and denominator degrees of freedom, and then computes a p-value for testing whether the two population variances are equal.\n\n\n\n\n\n\n\n\nNotePreview\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRestrict the data to Fire and Water types, build a two-level factor for the type, apply a built-in two-sample variance test using Attack as the response, and extract the single p-value from the test output.\n\n\n\n\ndf &lt;- read.csv(\"Pokemon.csv\")\ndf &lt;- subset(df, Type.1 %in% c(\"Fire\", \"Water\"))\ndf$grp &lt;- factor(df$Type.1, levels = c(\"Fire\", \"Water\"))\n\nres &lt;- var.test(Attack ~ grp, data = df)\nres$p.value\ndf &lt;- read.csv(\"Pokemon.csv\")\ndf &lt;- subset(df, Type.1 %in% c(\"Fire\", \"Water\"))\ndf$grp &lt;- factor(df$Type.1, levels = c(\"Fire\", \"Water\"))\n\nres &lt;- var.test(Attack ~ grp, data = df)\nres$p.value"
  },
  {
    "objectID": "tutorials/tutorial_05.html#q1-pooled-equal-variances-reviews",
    "href": "tutorials/tutorial_05.html#q1-pooled-equal-variances-reviews",
    "title": "Tutorial 05: Two Sample Confidence Intervals",
    "section": "Q1 — Pooled (Equal Variances): Reviews",
    "text": "Q1 — Pooled (Equal Variances): Reviews\nUsing the local file recipe_reviews.csv, compute a 95% two-sided confidence interval for \\[ \\mu_{FiveStar} - \\mu_{NotFive}\\] where the outcome is best_score and the groups are stars == 5 (FiveStar) vs stars != 5 (NotFive). Read the CSV with read.csv(“recipe_reviews.csv”), build the two groups, and print the 2-element vector c(lower, upper).\n\n\n\nPhoto by Maximus Mazar on Unsplash\n\n\n\n\n\n\n\n\nNoteInfo\n\n\n\nFor a pooled two-sample CI with equal variances:\n\\[ \\bar{x}_1 - \\bar{x}_2 \\ \\ \\pm \\ \\ t^*_{df=n_1 + n_2 - 2} s_p \\sqrt{\\frac{1}{n1} + \\frac{1}{n2}}, \\ \\ s^2_p = \\frac{(n_1 - 1)s^2_1 + (n_2-1)s^2_2}{n_1 + n_2 - 2}\\] Use \\(\\alpha\\) = 0.05 \\(\\implies t^* = t_{1 - \\frac{\\alpha}{2}, df}\\)\nGroup 1 = FiveStar (rows with stars == 5), Group 2 = NotFive (rows with stars != 5).\n\n\n\n\n\n\n\n\nNotePreview\n\n\n\nThe “Recipe Reviews and User Feedback Dataset” is a comprehensive repository of data encompassing various aspects of recipe reviews and user interactions. It includes essential information such as the recipe name, its ranking on the top 100 recipes list, a unique recipe code, and user details like user ID, user name, and an internal user reputation score. Each review comment is uniquely identified with a comment ID and comes with additional attributes, including the creation timestamp, reply count, and the number of up-votes and down-votes received. Users’ sentiment towards recipes is quantified on a 1 to 5 star rating scale, with a score of 0 denoting an absence of rating. This dataset is a valuable resource for researchers and data scientists, facilitating endeavors in sentiment analysis, user behavior analysis, recipe recommendation systems, and more. It offers a window into the dynamics of recipe reviews and user feedback within the culinary website domain.\nRun this code chunk to get a glimpse of the dataset. Feel free to change the values to visualize more/less number of rows.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nConfirm you’re comparing the means of two groups formed by a boolean condition on stars. Use the pooled-variance standard error and the appropriate two-sided t critical value for a 95% interval. Print just the lower and upper bounds as a numeric vector.\n\n\n\n\ndf &lt;- read.csv(\"recipe_reviews.csv\")\n\nx1 &lt;- subset(df, stars == 5)$best_score\nx2 &lt;- subset(df, stars != 5)$best_score\n\nn1 &lt;- sum(!is.na(x1)); n2 &lt;- sum(!is.na(x2))\nm1 &lt;- mean(x1, na.rm = TRUE); m2 &lt;- mean(x2, na.rm = TRUE)\ns1 &lt;- stats::sd(x1, na.rm = TRUE); s2 &lt;- stats::sd(x2, na.rm = TRUE)\n\ndfree &lt;- n1 + n2 - 2\nsp2 &lt;- (((n1 - 1) * s1^2) + ((n2 - 1) * s2^2)) / dfree\nsp &lt;- sqrt(sp2)\n\ntstar &lt;- qt(0.975, dfree)\nse &lt;- sp * sqrt(1/n1 + 1/n2)\nest &lt;- m1 - m2\n\nc(est - tstar*se, est + tstar*se)\ndf &lt;- read.csv(\"recipe_reviews.csv\")\n\nx1 &lt;- subset(df, stars == 5)$best_score\nx2 &lt;- subset(df, stars != 5)$best_score\n\nn1 &lt;- sum(!is.na(x1)); n2 &lt;- sum(!is.na(x2))\nm1 &lt;- mean(x1, na.rm = TRUE); m2 &lt;- mean(x2, na.rm = TRUE)\ns1 &lt;- stats::sd(x1, na.rm = TRUE); s2 &lt;- stats::sd(x2, na.rm = TRUE)\n\ndfree &lt;- n1 + n2 - 2\nsp2 &lt;- (((n1 - 1) * s1^2) + ((n2 - 1) * s2^2)) / dfree\nsp &lt;- sqrt(sp2)\n\ntstar &lt;- qt(0.975, dfree)\nse &lt;- sp * sqrt(1/n1 + 1/n2)\nest &lt;- m1 - m2\n\nc(est - tstar*se, est + tstar*se)"
  },
  {
    "objectID": "tutorials/tutorial_05.html#q2-pooled-equal-variances-using-t.test",
    "href": "tutorials/tutorial_05.html#q2-pooled-equal-variances-using-t.test",
    "title": "Tutorial 05: Two Sample Confidence Intervals",
    "section": "Q2 — Pooled (Equal Variances): Using t.test()",
    "text": "Q2 — Pooled (Equal Variances): Using t.test()\nCompute a 90% two-sided confidence interval for \\[ \\mu_{Adelie} - \\mu_{Gentoo}\\] for bill length (mm) using pooled variances. Use the local file penguins.csv and only the two species Adelie and Gentoo.\n\n\n\nPhoto by Adam Tarshis on Unsplash\n\n\n\n\n\n\n\n\nNoteInfo\n\n\n\nFor equal-variance two-sample CIs, t.test(yield ~ method, var.equal = TRUE, conf.level = 0.90) uses the pooled standard error and df = \\(n_1 + n_2 - 2\\). To get the CI for Adelie − Gentoo, set the factor level order to c(“Adelie”,“Gentoo”).\n\n\n\n\n\n\n\n\nNotePreview\n\n\n\nRun this code chunk to get a glimpse of the dataset. Feel free to change the values to visualize more/less number of rows.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNoteInfo\n\n\n\nWhen σ is known, \\[\n\\mathrm{CI}_{1-\\alpha}:\\ \\bar{x} \\pm x_{1-\\alpha/2}\\,\\frac{\\sigma}{\\sqrt{n}}.\n\\]\n\n\n\n\n\n\n\n\n\n\n\nUse a two-group factor for the species and the pooled-variance option in t.test. Ensure you’re returning just the interval bounds, not the whole test object.\n\n\n\n\ndf &lt;- read.csv(\"penguins.csv\")\nkeep &lt;- df$species %in% c(\"Adelie\",\"Gentoo\")\ndf &lt;- subset(df, keep & !is.na(bill_length_mm))\n\ndf$method &lt;- factor(df$species, levels = c(\"Adelie\",\"Gentoo\")) # order matters for the contrast\ndf$yield &lt;- df$bill_length_mm\n\ntt &lt;- t.test(yield ~ method, data = df, var.equal = TRUE, conf.level = 0.90)\ntt$conf.int\ndf &lt;- read.csv(\"penguins.csv\")\nkeep &lt;- df$species %in% c(\"Adelie\",\"Gentoo\")\ndf &lt;- subset(df, keep & !is.na(bill_length_mm))\n\ndf$method &lt;- factor(df$species, levels = c(\"Adelie\",\"Gentoo\")) # order matters for the contrast\ndf$yield &lt;- df$bill_length_mm\n\ntt &lt;- t.test(yield ~ method, data = df, var.equal = TRUE, conf.level = 0.90)\ntt$conf.int"
  },
  {
    "objectID": "tutorials/tutorial_05.html#q3-welch-unequal-variances-using-t.test",
    "href": "tutorials/tutorial_05.html#q3-welch-unequal-variances-using-t.test",
    "title": "Tutorial 05: Two Sample Confidence Intervals",
    "section": "Q3 — Welch (Unequal Variances): Using t.test()",
    "text": "Q3 — Welch (Unequal Variances): Using t.test()\nCompute an 80% two-sided confidence interval for \\[ \\mu_{Chinstrap} - \\mu_{Gentoo}\\] for flipper_length_mm using Welch’s unequal-variance method (the default in t.test). Use the local file penguins.csv and only the species Chinstrap and Gentoo. Print only the 2-number CI vector.\n\n\n\n\n\n\nNoteInfo\n\n\n\nt.test(y ~ g, conf.level = 0.80) uses Welch by default (var.equal = FALSE). To obtain Chinstrap − Gentoo, set the factor level order to c(“Chinstrap”,“Gentoo”).\n\n\n\n\n\n\n\n\nNotePreview\n\n\n\nRun this code chunk to get a glimpse of the dataset. Feel free to change the values to visualize more/less number of rows.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEnsure you keep exactly two species and set their order to match the contrast. Return just the two CI bounds from the test result.\n\n\n\n\n\ndf &lt;- read.csv(\"penguins.csv\")\n\nkeep &lt;- df$species %in% c(\"Chinstrap\",\"Gentoo\")\ndf &lt;- subset(df, keep & !is.na(flipper_length_mm))\n\ndf$method &lt;- factor(df$species, levels = c(\"Chinstrap\",\"Gentoo\"))\ndf$y &lt;- df$flipper_length_mm\n\ntt &lt;- t.test(y ~ method, data = df, conf.level = 0.80) # Welch by default\ntt$conf.int\n\ndf &lt;- read.csv(\"penguins.csv\")\n\nkeep &lt;- df$species %in% c(\"Chinstrap\",\"Gentoo\")\ndf &lt;- subset(df, keep & !is.na(flipper_length_mm))\n\ndf$method &lt;- factor(df$species, levels = c(\"Chinstrap\",\"Gentoo\"))\ndf$y &lt;- df$flipper_length_mm\n\ntt &lt;- t.test(y ~ method, data = df, conf.level = 0.80) # Welch by default\ntt$conf.int"
  },
  {
    "objectID": "tutorials/tutorial_05.html#q4-two-sample-ci-for-a-difference-of-proportions",
    "href": "tutorials/tutorial_05.html#q4-two-sample-ci-for-a-difference-of-proportions",
    "title": "Tutorial 05: Two Sample Confidence Intervals",
    "section": "Q4 — Two-Sample CI for a Difference of Proportions",
    "text": "Q4 — Two-Sample CI for a Difference of Proportions\nIn recipe_reviews.csv, compare the proportion of reviews where thumbs_up &gt; thumbs_down between FiveStar (stars == 5) and NotFive (stars != 5). Compute a 95% two-sided CI for \\[p_{FiveStar} - p_{NotFive}\\]. Print c(lower, uppper).\n\n\n\n\n\n\nNotePreview\n\n\n\nRun this code chunk to get a glimpse of the dataset. Feel free to change the values to visualize more/less number of rows.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNoteInfo\n\n\n\nCI for difference of proportions: \\[\n\\mathrm{CI}_{1-\\alpha}:\\ \\hat{p_1} - \\hat{p_2} \\pm z_{1-\\alpha/2} * \\sqrt{\\frac{\\hat{p_1}(1-\\hat{p_1})}{n_1} + \\frac{\\hat{p_2}(1-\\hat{p_2})}{n_2}}.\n\\]\n\n\n\n\n\n\n\n\n\n\n\nCompute \\[\\hat{p}\\] per group, then compute their SE and z* at 0.975.\n\n\n\n\ndf &lt;- read.csv(\"recipe_reviews.csv\")\ng1 &lt;- subset(df, stars == 5) #segregating the dataset\ng2 &lt;- subset(df, stars != 5)\ncount1 &lt;- as.integer(g1$thumbs_up &gt; g1$thumbs_down)\ncount2 &lt;- as.integer(g2$thumbs_up &gt; g2$thumbs_down)\nn1 &lt;- sum(is.finite(count1)); n2 &lt;- sum(is.finite(count2))\np1 &lt;- mean(count1, na.rm = TRUE); p2 &lt;- mean(count2, na.rm = TRUE)\nse &lt;- sqrt(p1*(1-p1)/n1 + p2*(1-p2)/n2)\nz &lt;- qnorm(0.975); \n(p1 - p2) + c(-1,1)*z*se\ndf &lt;- read.csv(\"recipe_reviews.csv\")\ng1 &lt;- subset(df, stars == 5) #segregating the dataset\ng2 &lt;- subset(df, stars != 5)\ncount1 &lt;- as.integer(g1$thumbs_up &gt; g1$thumbs_down)\ncount2 &lt;- as.integer(g2$thumbs_up &gt; g2$thumbs_down)\nn1 &lt;- sum(is.finite(count1)); n2 &lt;- sum(is.finite(count2))\np1 &lt;- mean(count1, na.rm = TRUE); p2 &lt;- mean(count2, na.rm = TRUE)\nse &lt;- sqrt(p1*(1-p1)/n1 + p2*(1-p2)/n2)\nz &lt;- qnorm(0.975); \n(p1 - p2) + c(-1,1)*z*se"
  },
  {
    "objectID": "tutorials/tutorial_05.html#q5-two-sample-ci-for-a-difference-of-proportions-using-prop.test",
    "href": "tutorials/tutorial_05.html#q5-two-sample-ci-for-a-difference-of-proportions-using-prop.test",
    "title": "Tutorial 05: Two Sample Confidence Intervals",
    "section": "Q5 — Two-Sample CI for a Difference of Proportions using prop.test",
    "text": "Q5 — Two-Sample CI for a Difference of Proportions using prop.test\nIn penguins.csv, compare the male proportion between Chinstrap and Gentoo. Compute an evidence-only CI (no hypothesis interpretation needed) for \\(p_{Chinstrap} - p_{Gentoo}\\) at 90% and print c(lower upper).\n\n\n\n\n\n\nNotePreview\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNoteInfo\n\n\n\nThe prop.test() function in R performs tests of proportions, allowing for the comparison of proportions across groups or against specific values. Here is an example according to this question. here’s a super simple one-sample prop.test using penguins.csv. It asks: among Gentoo penguins, what fraction are male? It prints the estimate and a 95% CI. Run the code to see!\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFilter to two species, count “male” in each, and feed (x1,n1),(x2,n2) to prop.test.\n\n\n\n\ndf &lt;- read.csv(\"penguins.csv\")\ndf &lt;- subset(df, species %in% c(\"Chinstrap\",\"Gentoo\") & !is.na(sex))\nx1 &lt;- sum(df$species==\"Chinstrap\" & df$sex==\"male\")\nn1 &lt;- sum(df$species==\"Chinstrap\")\nx2 &lt;- sum(df$species==\"Gentoo\" & df$sex==\"male\")\nn2 &lt;- sum(df$species==\"Gentoo\")\nprop.test(x = c(x1, x2), n = c(n1, n2), conf.level = 0.90, correct = FALSE)$conf.int\ndf &lt;- read.csv(\"penguins.csv\")\ndf &lt;- subset(df, species %in% c(\"Chinstrap\",\"Gentoo\") & !is.na(sex))\nx1 &lt;- sum(df$species==\"Chinstrap\" & df$sex==\"male\")\nn1 &lt;- sum(df$species==\"Chinstrap\")\nx2 &lt;- sum(df$species==\"Gentoo\" & df$sex==\"male\")\nn2 &lt;- sum(df$species==\"Gentoo\")\nprop.test(x = c(x1, x2), n = c(n1, n2), conf.level = 0.90, correct = FALSE)$conf.int"
  },
  {
    "objectID": "tutorials/tutorial_05.html#q6-two-sample-ci-for-a-difference-of-proportions-islandbiscoe",
    "href": "tutorials/tutorial_05.html#q6-two-sample-ci-for-a-difference-of-proportions-islandbiscoe",
    "title": "Tutorial 05: Two Sample Confidence Intervals",
    "section": "Q6 — Two-Sample CI for a Difference of Proportions (island=Biscoe)",
    "text": "Q6 — Two-Sample CI for a Difference of Proportions (island=Biscoe)\nUsing penguins.csv, compare the proportion of penguins on Biscoe island between Adelie and Gentoo. Compute a 95% two-sided CI for \\(p_{Adelie} - p_{Gentoo}\\) and print c(lower upper).\n\n\n\n\n\n\nNotePreview\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCount “Biscoe” within each species to get x1, x2. Use totals for n1, n2, then prop.test(…)$conf.int. Order your counts as (Adelie, Gentoo) to get Adelie − Gentoo.\n\n\n\n\ndf &lt;- read.csv(\"penguins.csv\")\nsub &lt;- subset(df, species %in% c(\"Adelie\",\"Gentoo\") & !is.na(island))\nx1 &lt;- sum(sub$species==\"Adelie\" & sub$island==\"Biscoe\"); n1 &lt;- sum(sub$species==\"Adelie\")\nx2 &lt;- sum(sub$species==\"Gentoo\" & sub$island==\"Biscoe\"); n2 &lt;- sum(sub$species==\"Gentoo\")\nprop.test(x=c(x1,x2), n=c(n1,n2), conf.level=0.95, correct=FALSE)$conf.int\ndf &lt;- read.csv(\"penguins.csv\")\nsub &lt;- subset(df, species %in% c(\"Adelie\",\"Gentoo\") & !is.na(island))\nx1 &lt;- sum(sub$species==\"Adelie\" & sub$island==\"Biscoe\"); n1 &lt;- sum(sub$species==\"Adelie\")\nx2 &lt;- sum(sub$species==\"Gentoo\" & sub$island==\"Biscoe\"); n2 &lt;- sum(sub$species==\"Gentoo\")\nprop.test(x=c(x1,x2), n=c(n1,n2), conf.level=0.95, correct=FALSE)$conf.int"
  },
  {
    "objectID": "tutorials/tutorial_05.html#q7-two-sample-ci-for-a-ratio-of-variances-manual-f-based",
    "href": "tutorials/tutorial_05.html#q7-two-sample-ci-for-a-ratio-of-variances-manual-f-based",
    "title": "Tutorial 05: Two Sample Confidence Intervals",
    "section": "Q7 — Two-Sample CI for a Ratio of Variances (manual F-based)",
    "text": "Q7 — Two-Sample CI for a Ratio of Variances (manual F-based)\nUsing recipe_reviews.csv, compare the variance of best_score for FiveStar vs NotFive. Build a 95% CI for \\(\\sigma^2_{FiveStar} / \\sigma^2_{NotFive}\\) and print c(lower, upper).\n\n\n\n\n\n\nNotePreview\n\n\n\nHere is a glimpse of the dataset:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNoteInfo\n\n\n\nTaking group 1 as FiveStar here, with \\(s_1^2\\) and \\(s_2^2\\) as sample variances, here is the CI: \\[\n\\text{CI}_{1-\\alpha}\\!\\left(\\frac{\\sigma_1^2}{\\sigma_2^2}\\right)\n=\n\\left(\n\\frac{{s_1^2}/{s_2^2}}{F_{1-\\alpha/2,\\,df_1,\\,df_2}},\n\\;\n\\frac{{s_1^2}/{s_2^2}}{F_{\\alpha/2,\\,df_1,\\,df_2}}\n\\right),\n\\qquad df_1=n_1-1,\\; df_2=n_2-1.\n\\]\n\n\n\n\n\n\n\n\n\n\n\nUse FiveStar as numerator. Compute \\(s_1^2\\) and \\(s_2^2\\) and divide by the F cutoffs (0.975 and 0.025).\n\n\n\n\ndf &lt;- read.csv(\"recipe_reviews.csv\")\nx1 &lt;- subset(df, stars == 5)$best_score\nx2 &lt;- subset(df, stars != 5)$best_score\nx1 &lt;- x1[is.finite(x1)]\nx2 &lt;- x2[is.finite(x2)]\nn1 &lt;- length(x1)\nn2 &lt;- length(x2)\ns1 &lt;- stats::var(x1)\ns2 &lt;- stats::var(x2)\ndf1 &lt;- n1 - 1\ndf2 &lt;- n2 - 1\nratio &lt;- s1/s2\nF_lo &lt;- qf(0.975, df1, df2)\nF_hi &lt;- qf(0.025, df1, df2)\nc(ratio/F_lo, ratio/F_hi)\ndf &lt;- read.csv(\"recipe_reviews.csv\")\nx1 &lt;- subset(df, stars == 5)$best_score\nx2 &lt;- subset(df, stars != 5)$best_score\nx1 &lt;- x1[is.finite(x1)]\nx2 &lt;- x2[is.finite(x2)]\nn1 &lt;- length(x1)\nn2 &lt;- length(x2)\ns1 &lt;- stats::var(x1)\ns2 &lt;- stats::var(x2)\ndf1 &lt;- n1 - 1\ndf2 &lt;- n2 - 1\nratio &lt;- s1/s2\nF_lo &lt;- qf(0.975, df1, df2)\nF_hi &lt;- qf(0.025, df1, df2)\nc(ratio/F_lo, ratio/F_hi)"
  },
  {
    "objectID": "tutorials/tutorial_05.html#q8---two-sample-ci-for-a-ratio-of-variances-using-var.test",
    "href": "tutorials/tutorial_05.html#q8---two-sample-ci-for-a-ratio-of-variances-using-var.test",
    "title": "Tutorial 05: Two Sample Confidence Intervals",
    "section": "Q8 - Two-Sample CI for a Ratio of Variances using var.test",
    "text": "Q8 - Two-Sample CI for a Ratio of Variances using var.test\nIn penguins.csv, compare variance of bill_length_mm between Adelie (group 1) and Gentoo (group 2). Compute an 80% CI for \\(\\sigma^2_{Adelie} / \\sigma^2_{Gentoo}\\) using var.test and print the two bounds.\n\n\n\n\n\n\nNoteInfo\n\n\n\nHere is an example to demonstrate how var.test works. We are taking the recipe reviews dataset to showcase the usage. Run the code to view results.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNotePreview\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFilter to Adelie and Gentoo, remove NAs, then feed the two numeric vectors to var.test.\n\n\n\n\ndf &lt;- read.csv(\"penguins.csv\")\ndf &lt;- subset(df, species %in% c(\"Adelie\",\"Gentoo\") & !is.na(bill_length_mm))\nx &lt;- df$bill_length_mm[df$species==\"Adelie\"]\ny &lt;- df$bill_length_mm[df$species==\"Gentoo\"]\nvar.test(x, y, conf.level = 0.80)$conf.int\ndf &lt;- read.csv(\"penguins.csv\")\ndf &lt;- subset(df, species %in% c(\"Adelie\",\"Gentoo\") & !is.na(bill_length_mm))\nx &lt;- df$bill_length_mm[df$species==\"Adelie\"]\ny &lt;- df$bill_length_mm[df$species==\"Gentoo\"]\nvar.test(x, y, conf.level = 0.80)$conf.int"
  },
  {
    "objectID": "tutorials/tutorial_10.html#q1---fit-the-regression-model",
    "href": "tutorials/tutorial_10.html#q1---fit-the-regression-model",
    "title": "Tutorial 10: Inference Techniques on Regression",
    "section": "Q1 - Fit the Regression Model",
    "text": "Q1 - Fit the Regression Model\nFor this tutorial, we will be using a Life Expectancy dataset from the World Health Organization (WHO). From your tutorial 9 knowledge, fit a simple linear regression model with Life Expectancy as X and Schooling as Y. Return the estimated slope.\n\n\n\nPhoto by Kenny Eliason on Unsplash\n\n\n\n\n\n\n\n\nNotePreview\n\n\n\nFeel free to run this code block to visualize the data.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFill coef(model)[___] with right column name.\n\n\n\n\n\ndf &lt;- read.csv(\"life_expectancy.csv\", check.names=FALSE)\nnames(df) &lt;- trimws(names(df))\nle &lt;- df[, c(\"Life expectancy\",\"Schooling\")]\nnames(le) &lt;- c(\"life_exp\",\"schooling\")\nle &lt;- na.omit(le)\n\nmodel &lt;- lm(life_exp ~ schooling, data = le)\ncoef(model)[\"schooling\"]\n\ndf &lt;- read.csv(\"life_expectancy.csv\", check.names=FALSE)\nnames(df) &lt;- trimws(names(df))\nle &lt;- df[, c(\"Life expectancy\",\"Schooling\")]\nnames(le) &lt;- c(\"life_exp\",\"schooling\")\nle &lt;- na.omit(le)\n\nmodel &lt;- lm(life_exp ~ schooling, data = le)\ncoef(model)[\"schooling\"]"
  },
  {
    "objectID": "tutorials/tutorial_10.html#q2-interpret-the-slope",
    "href": "tutorials/tutorial_10.html#q2-interpret-the-slope",
    "title": "Tutorial 10: Inference Techniques on Regression",
    "section": "Q2 — Interpret the slope:",
    "text": "Q2 — Interpret the slope:\nA policy increases schooling by 2 years for every country. Using the fitted regression model, compute the predicted change in life expectancy caused by this policy.\nDo this in two ways:\n\nCompute two fitted values at \\(x_0\\) and \\(x_0 + 2\\), then take the difference. \nUse the model’s slope to compute the same change.\n\n\n\n\nPhoto by MD Duran on Unsplash\n\n\n\n\n\n\n\n\nNoteInfo\n\n\n\nIn a simple linear regression line, the “effect” of increasing (x) by a fixed amount (x) can be seen by comparing fitted values at two (x)-values separated by (x).\nA good way to sanity-check an interpretation is to compute the same effect using (1) fitted values and (2) the slope coefficient, and confirm they agree.\n\n\n\n\n\n\n\n\nNotePreview\n\n\n\nFeel free to run this code block to visualize the data.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUse the idea “effect = fitted value at (new x) minus fitted value at (old x)”. You can get fitted values either from the line equation or from predict() using newdata. For the slope method, interpret the slope as “change in fitted response per 1 unit of x”.\n\n\n\n\ndf &lt;- read.csv(\"life_expectancy.csv\", check.names = FALSE)\nnames(df) &lt;- trimws(names(df))\n\nle &lt;- df[, c(\"Life expectancy\",\"Schooling\")]\nnames(le) &lt;- c(\"life_exp\",\"schooling\")\nle &lt;- na.omit(le)\n\nmodel &lt;- lm(life_exp ~ schooling, data = le)\n\nx0 &lt;- mean(le$schooling)\n\nyhat0 &lt;- unname(predict(model, newdata = data.frame(schooling = x0)))\nyhat2 &lt;- unname(predict(model, newdata = data.frame(schooling = x0 + 2)))\neffect_via_preds &lt;- yhat2 - yhat0\n\nb1 &lt;- unname(coef(model)[\"schooling\"])\neffect_via_slope &lt;- 2 * b1\n\nc(effect_via_preds = effect_via_preds,\neffect_via_slope = effect_via_slope)\ndf &lt;- read.csv(\"life_expectancy.csv\", check.names = FALSE)\nnames(df) &lt;- trimws(names(df))\n\nle &lt;- df[, c(\"Life expectancy\",\"Schooling\")]\nnames(le) &lt;- c(\"life_exp\",\"schooling\")\nle &lt;- na.omit(le)\n\nmodel &lt;- lm(life_exp ~ schooling, data = le)\n\nx0 &lt;- mean(le$schooling)\n\nyhat0 &lt;- unname(predict(model, newdata = data.frame(schooling = x0)))\nyhat2 &lt;- unname(predict(model, newdata = data.frame(schooling = x0 + 2)))\neffect_via_preds &lt;- yhat2 - yhat0\n\nb1 &lt;- unname(coef(model)[\"schooling\"])\neffect_via_slope &lt;- 2 * b1\n\nc(effect_via_preds = effect_via_preds,\neffect_via_slope = effect_via_slope)"
  },
  {
    "objectID": "tutorials/tutorial_10.html#q3-compute-r2",
    "href": "tutorials/tutorial_10.html#q3-compute-r2",
    "title": "Tutorial 10: Inference Techniques on Regression",
    "section": "Q3 — Compute \\(R^2\\)",
    "text": "Q3 — Compute \\(R^2\\)\nReturn the model’s \\(R^2\\)\n\n\n\n\n\n\nNoteInfo\n\n\n\n\\(R^2\\) is the proportion of variability in life expectancy explained by schooling.\n\n\n\n\n\n\n\n\nNotePreview\n\n\n\nFeel free to run this code block to visualize the data.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nProduce model summary and return the appropriate statistic from it.\n\n\n\n\ndf &lt;- read.csv(\"life_expectancy.csv\", check.names = FALSE)\nnames(df) &lt;- trimws(names(df))\nle &lt;- df[, c(\"Life expectancy\",\"Schooling\")]\nnames(le) &lt;- c(\"life_exp\",\"schooling\")\nle &lt;- na.omit(le)\nmodel &lt;- lm(life_exp ~ schooling, data = le)\n\nsummary(model)$r.squared\ndf &lt;- read.csv(\"life_expectancy.csv\", check.names = FALSE)\nnames(df) &lt;- trimws(names(df))\nle &lt;- df[, c(\"Life expectancy\",\"Schooling\")]\nnames(le) &lt;- c(\"life_exp\",\"schooling\")\nle &lt;- na.omit(le)\nmodel &lt;- lm(life_exp ~ schooling, data = le)\n\nsummary(model)$r.squared"
  },
  {
    "objectID": "tutorials/tutorial_10.html#q4-computing-p-value",
    "href": "tutorials/tutorial_10.html#q4-computing-p-value",
    "title": "Tutorial 10: Inference Techniques on Regression",
    "section": "Q4 — Computing P-value",
    "text": "Q4 — Computing P-value\nCompute the p-value for \\(b_1\\) for testing \\(H_0: b_1 = 0\\).\n\n\n\n\n\n\nNoteInfo\n\n\n\nThis tests whether there is evidence of a linear relationship between schooling and life expectancy.\n\n\n\n\n\n\n\n\nNotePreview\n\n\n\nFeel free to run this code block to visualize the data.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe second argument in coefficients represents the column ‘Pr(&gt;|t|)’.\n\n\n\n\ndf &lt;- read.csv(\"life_expectancy.csv\", check.names = FALSE)\nnames(df) &lt;- trimws(names(df))\nle &lt;- df[, c(\"Life expectancy\",\"Schooling\")]\nnames(le) &lt;- c(\"life_exp\",\"schooling\")\nle &lt;- na.omit(le)\nmod &lt;- lm(life_exp ~ schooling, data = le)\n\nsummary(mod)$coefficients[\"schooling\", \"Pr(&gt;|t|)\"]\ndf &lt;- read.csv(\"life_expectancy.csv\", check.names = FALSE)\nnames(df) &lt;- trimws(names(df))\nle &lt;- df[, c(\"Life expectancy\",\"Schooling\")]\nnames(le) &lt;- c(\"life_exp\",\"schooling\")\nle &lt;- na.omit(le)\nmod &lt;- lm(life_exp ~ schooling, data = le)\n\nsummary(mod)$coefficients[\"schooling\", \"Pr(&gt;|t|)\"]"
  },
  {
    "objectID": "tutorials/tutorial_10.html#q5-95-ci-for-the-slope",
    "href": "tutorials/tutorial_10.html#q5-95-ci-for-the-slope",
    "title": "Tutorial 10: Inference Techniques on Regression",
    "section": "Q5 — 95% CI for the slope",
    "text": "Q5 — 95% CI for the slope\nReturn a 95% confidence interval for the slope using the R built-in command confint().\n\n\n\n\n\n\nNoteInfo\n\n\n\nThe confint() function in R is used to compute confidence intervals for one or more parameters in a fitted model.\n\n\n\n\n\n\n\n\nNotePreview\n\n\n\nFeel free to run this code block to visualize the data.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEnter the right column names and research how confint() is used here.\n\n\n\n\ndf &lt;- read.csv(\"life_expectancy.csv\", check.names = FALSE)\nnames(df) &lt;- trimws(names(df))\nle &lt;- df[, c(\"Life expectancy\",\"Schooling\")]\nnames(le) &lt;- c(\"life_exp\",\"schooling\")\nle &lt;- na.omit(le)\nmod &lt;- lm(life_exp ~ schooling, data = le)\n\nas.numeric(confint(mod, \"schooling\"))\ndf &lt;- read.csv(\"life_expectancy.csv\", check.names = FALSE)\nnames(df) &lt;- trimws(names(df))\nle &lt;- df[, c(\"Life expectancy\",\"Schooling\")]\nnames(le) &lt;- c(\"life_exp\",\"schooling\")\nle &lt;- na.omit(le)\nmod &lt;- lm(life_exp ~ schooling, data = le)\n\nas.numeric(confint(mod, \"schooling\"))"
  },
  {
    "objectID": "tutorials/tutorial_10.html#q6-predict-the-mean-life-expectancy",
    "href": "tutorials/tutorial_10.html#q6-predict-the-mean-life-expectancy",
    "title": "Tutorial 10: Inference Techniques on Regression",
    "section": "Q6 — Predict the mean life expectancy",
    "text": "Q6 — Predict the mean life expectancy\nPredict the mean life expectancy at schooling = 12 years.\n\n\n\nPhoto by Kenny Eliason on Unsplash\n\n\n\n\n\n\n\n\nNoteInfo\n\n\n\nA point prediction is essentially \\(\\hat{y}\\) at a certain x value. In this case, x=12.\n\n\n\n\n\n\n\n\nNotePreview\n\n\n\nFeel free to run this code block to visualize the data.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLook up how to use predict().\n\n\n\n\ndf &lt;- read.csv(\"life_expectancy.csv\", check.names = FALSE)\nnames(df) &lt;- trimws(names(df))\nle &lt;- df[, c(\"Life expectancy\",\"Schooling\")]\nnames(le) &lt;- c(\"life_exp\",\"schooling\")\nle &lt;- na.omit(le)\nmodel &lt;- lm(life_exp ~ schooling, data = le)\n\npredict(model, newdata = data.frame(schooling = 12))\ndf &lt;- read.csv(\"life_expectancy.csv\", check.names = FALSE)\nnames(df) &lt;- trimws(names(df))\nle &lt;- df[, c(\"Life expectancy\",\"Schooling\")]\nnames(le) &lt;- c(\"life_exp\",\"schooling\")\nle &lt;- na.omit(le)\nmodel &lt;- lm(life_exp ~ schooling, data = le)\n\npredict(model, newdata = data.frame(schooling = 12))"
  },
  {
    "objectID": "tutorials/tutorial_10.html#q7-residuals-sum",
    "href": "tutorials/tutorial_10.html#q7-residuals-sum",
    "title": "Tutorial 10: Inference Techniques on Regression",
    "section": "Q7 — Residuals sum",
    "text": "Q7 — Residuals sum\nConfirm if the residuals in the model sum to 0 or not. Round the sum.\n\n\n\n\n\n\nNoteInfo\n\n\n\nUsually with an intercept in the model, the residuals sum up to 0 (with a tiny numerical error).\n\n\n\n\n\n\n\n\nNotePreview\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUse resid() to get residuals.\n\n\n\n\ndf &lt;- read.csv(\"life_expectancy.csv\", check.names = FALSE)\nnames(df) &lt;- trimws(names(df))\nle &lt;- df[, c(\"Life expectancy\",\"Schooling\")]\nnames(le) &lt;- c(\"life_exp\",\"schooling\")\nle &lt;- na.omit(le)\nmodel &lt;- lm(life_exp ~ schooling, data = le)\n\nround(sum(resid(model)), 6)\ndf &lt;- read.csv(\"life_expectancy.csv\", check.names = FALSE)\nnames(df) &lt;- trimws(names(df))\nle &lt;- df[, c(\"Life expectancy\",\"Schooling\")]\nnames(le) &lt;- c(\"life_exp\",\"schooling\")\nle &lt;- na.omit(le)\nmodel &lt;- lm(life_exp ~ schooling, data = le)\n\nround(sum(resid(model)), 6)"
  },
  {
    "objectID": "tutorials/tutorial_10.html#q8-standardized-residuals",
    "href": "tutorials/tutorial_10.html#q8-standardized-residuals",
    "title": "Tutorial 10: Inference Techniques on Regression",
    "section": "Q8 — Standardized residuals",
    "text": "Q8 — Standardized residuals\nCompute standardized residuals and figure out how many satisfy the condition |\\(r_i\\)| &gt; 2.\n\n\n\n\n\n\nNoteInfo\n\n\n\nStandardized residuals are useful for spotting outliers in data. If the condition |\\(r_i\\)| &gt; 2 is satisfied, it could be a common red flag.\n\n\n\n\n\n\n\n\nNotePreview\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUse rstandard() to get standardized residuals.\n\n\n\n\ndf &lt;- read.csv(\"life_expectancy.csv\", check.names = FALSE)\nnames(df) &lt;- trimws(names(df))\nle &lt;- df[, c(\"Life expectancy\",\"Schooling\")]\nnames(le) &lt;- c(\"life_exp\",\"schooling\")\nle &lt;- na.omit(le)\nmodel &lt;- lm(life_exp ~ schooling, data = le)\n\nr &lt;- rstandard(model)\nsum(abs(r) &gt; 2)\ndf &lt;- read.csv(\"life_expectancy.csv\", check.names = FALSE)\nnames(df) &lt;- trimws(names(df))\nle &lt;- df[, c(\"Life expectancy\",\"Schooling\")]\nnames(le) &lt;- c(\"life_exp\",\"schooling\")\nle &lt;- na.omit(le)\nmodel &lt;- lm(life_exp ~ schooling, data = le)\n\nr &lt;- rstandard(model)\nsum(abs(r) &gt; 2)"
  },
  {
    "objectID": "tutorials/tutorial_03.html#q1-standard-normal---left-tail-probability",
    "href": "tutorials/tutorial_03.html#q1-standard-normal---left-tail-probability",
    "title": "Tutorial 03: Distributions",
    "section": "Q1 — Standard Normal - Left Tail Probability",
    "text": "Q1 — Standard Normal - Left Tail Probability\nCompute \\(P(Z &lt;= 1.25)\\), where \\(Z ∼ N(0,1)\\).\n\n\n\n\n\n\nNoteInfo\n\n\n\nRemember: R calculates area to the left unlike probability tables.\n\n\n\n\n\n\n\n\nNoteInfo\n\n\n\nThis is the graphical representation of the question:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUse pnorm.\n\n\n\n\npnorm(1.25)\npnorm(1.25)"
  },
  {
    "objectID": "tutorials/tutorial_03.html#q2-standard-normal---right-tail-probability",
    "href": "tutorials/tutorial_03.html#q2-standard-normal---right-tail-probability",
    "title": "Tutorial 03: Distributions",
    "section": "Q2 — Standard Normal - Right Tail Probability",
    "text": "Q2 — Standard Normal - Right Tail Probability\nCompute \\(P(Z &gt;= 1.25)\\), where \\(Z ∼ N(0,1)\\).\n\n\n\n\n\n\nNoteInfo\n\n\n\nRemember: R calculates area to the left unlike probability tables.\n\n\n\n\n\n\n\n\nNoteInfo\n\n\n\nThis is the graphical representation of the question:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\npnorm gives area to the left. Remember, we need area to the right.\n\n\n\n\n1 - pnorm(1.25)\n1 - pnorm(1.25)"
  },
  {
    "objectID": "tutorials/tutorial_03.html#q3-standard-normal---two-sided-probability",
    "href": "tutorials/tutorial_03.html#q3-standard-normal---two-sided-probability",
    "title": "Tutorial 03: Distributions",
    "section": "Q3 — Standard Normal - Two-Sided Probability",
    "text": "Q3 — Standard Normal - Two-Sided Probability\nCompute \\(P(∣Z∣ &gt;= 1.25)\\), where \\(Z ∼ N(0,1)\\).\n\n\n\n\n\n\nNoteInfo\n\n\n\nRemember: R calculates area to the left unlike probability tables.\n\n\n\n\n\n\n\n\nNoteInfo\n\n\n\nThis is the graphical representation of the question:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEffectively use pnorm.\n\n\n\n\np_two &lt;- 2 * (1 - pnorm(1.25))\np_two &lt;- 2 * (1 - pnorm(1.25))"
  },
  {
    "objectID": "tutorials/tutorial_03.html#q4-normal-quantile-critical-value",
    "href": "tutorials/tutorial_03.html#q4-normal-quantile-critical-value",
    "title": "Tutorial 03: Distributions",
    "section": "Q4 — Normal Quantile (Critical Value)",
    "text": "Q4 — Normal Quantile (Critical Value)\nCompute \\(Z_{0.975}\\) where \\(Z ∼ N(0,1)\\).\n\n\n\n\n\n\nNoteInfo\n\n\n\nThis is the graphical representation of the question:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUse qnorm.\n\n\n\n\nqnorm(0.975)\nqnorm(0.975)"
  },
  {
    "objectID": "tutorials/tutorial_03.html#q5-t-distribution---right-tailed",
    "href": "tutorials/tutorial_03.html#q5-t-distribution---right-tailed",
    "title": "Tutorial 03: Distributions",
    "section": "Q5 — T-distribution - Right Tailed",
    "text": "Q5 — T-distribution - Right Tailed\nLet \\(T ∼ t_{10}\\). Compute \\(P(T &gt;= 1.5 )\\).\n\n\n\n\n\n\nNoteInfo\n\n\n\nThis is the graphical representation of the question:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUse pt.\n\n\n\n\n1 - pt(1.5, df = 10)\n1 - pt(1.5, df = 10)"
  },
  {
    "objectID": "tutorials/tutorial_03.html#q6-t-quantile---left-probability",
    "href": "tutorials/tutorial_03.html#q6-t-quantile---left-probability",
    "title": "Tutorial 03: Distributions",
    "section": "Q6 — T Quantile - Left Probability",
    "text": "Q6 — T Quantile - Left Probability\nFind \\(t^*\\) such that \\(P(T &lt;= t^*)\\) = 0.975, where \\(T ∼ t_{10}\\).\n\n\n\n\n\n\nNoteInfo\n\n\n\nThis is the graphical representation of the question:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUse qt.\n\n\n\n\nqt(0.975, df = 10)\nqt(0.975, df = 10)"
  },
  {
    "objectID": "tutorials/tutorial_03.html#q7-chi-square-distribution---right-tailed",
    "href": "tutorials/tutorial_03.html#q7-chi-square-distribution---right-tailed",
    "title": "Tutorial 03: Distributions",
    "section": "Q7 — Chi-Square Distribution - Right Tailed",
    "text": "Q7 — Chi-Square Distribution - Right Tailed\nLet \\(X ∼ {\\chi^2}_{8}\\). Compute \\(P(X &gt;= 15 )\\).\n\n\n\n\n\n\nNoteInfo\n\n\n\nThis is the graphical representation of the question:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUse pchisq.\n\n\n\n\n1 - pchisq(15, df = 8)\n1 - pchisq(15, df = 8)"
  },
  {
    "objectID": "tutorials/tutorial_03.html#q8-chi-square-quantile---left-probability",
    "href": "tutorials/tutorial_03.html#q8-chi-square-quantile---left-probability",
    "title": "Tutorial 03: Distributions",
    "section": "Q8 — Chi-Square Quantile - Left Probability",
    "text": "Q8 — Chi-Square Quantile - Left Probability\nFind \\(x^*\\) such that \\(P(X &lt;= x^*)\\) = 0.95, where \\(X ∼ {\\chi^2}_{8}\\).\n\n\n\n\n\n\nNoteInfo\n\n\n\nThis is the graphical representation of the question:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUse qchisq.\n\n\n\n\nqchisq(0.95, df = 10)\nqchisq(0.95, df = 10)"
  },
  {
    "objectID": "tutorials/tutorial_03.html#q9-f-distribution---right-tail",
    "href": "tutorials/tutorial_03.html#q9-f-distribution---right-tail",
    "title": "Tutorial 03: Distributions",
    "section": "Q9 — F Distribution - Right Tail",
    "text": "Q9 — F Distribution - Right Tail\nLet \\(F ∼ F_{5, 12}\\). Compute \\(P(F \\ge 3)\\).\n\n\n\n\n\n\nNoteInfo\n\n\n\nThis is the graphical representation of the question:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUse pf.\n\n\n\n\n1 - pf(3, df1=5, df2=12)\n1 - pf(3, df1=5, df2=12)"
  },
  {
    "objectID": "tutorials/tutorial_03.html#q10-f-quantile---left-probability",
    "href": "tutorials/tutorial_03.html#q10-f-quantile---left-probability",
    "title": "Tutorial 03: Distributions",
    "section": "Q10 — F Quantile - Left Probability",
    "text": "Q10 — F Quantile - Left Probability\nFind \\(f^*\\) such that \\(P(F &lt;= f^*)\\) = 0.95, where \\(F ∼ F_{3, 20}\\).\n\n\n\n\n\n\nNoteInfo\n\n\n\nThis is the graphical representation of the question:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUse qf.\n\n\n\n\nqf(0.95, df1=3, df2=20)\nqf(0.95, df1=3, df2=20)"
  },
  {
    "objectID": "tutorials/tutorial_03.html#q11-overview-with-skimr",
    "href": "tutorials/tutorial_03.html#q11-overview-with-skimr",
    "title": "Tutorial 03: Distributions",
    "section": "Q11 — Overview with Skimr",
    "text": "Q11 — Overview with Skimr\nThe question below has a dataframe df created from the dataset msleep that contains data about mammal sleep traits. Make a skim summary of df and store it in ms_skim. Print it to see your result!\n\n\n\nPhoto by Mpho Mojapelo on Unsplash\n\n\n\n\n\n\n\n\nNoteInfo\n\n\n\nInfo : skimr is an R package that provides summary statistics a user can quickly skim to understand their data.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUse the skim function from skimr.\n\n\n\n\nlibrary(ggplot2)\nlibrary(skimr)\ndf &lt;- msleep\nms_skim &lt;- skim(df)\nms_skim\nlibrary(ggplot2)\nlibrary(skimr)\ndf &lt;- msleep\nms_skim &lt;- skim(df)\nms_skim"
  },
  {
    "objectID": "tutorials/tutorial_03.html#q12-histogram-with-ggplot",
    "href": "tutorials/tutorial_03.html#q12-histogram-with-ggplot",
    "title": "Tutorial 03: Distributions",
    "section": "Q12 — Histogram with ggplot",
    "text": "Q12 — Histogram with ggplot\nBuild a ggplot histogram of sleep_total with binwidth = 1 by replacing the ＿＿ with the correct answer. Save the plot to p_hist. Fill the histogram with any color of your choice!\n\n\n\n\n\n\nNoteInfo\n\n\n\nInfo : ggplot refers to the ggplot2 package in R, a powerful tool for creating statistical graphics.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLook up how to make plots with ggplot.\n\n\n\n\nlibrary(ggplot2)\np_hist &lt;- ggplot(df, aes(sleep_total)) +\n  geom_histogram(binwidth = 1)\np_hist\nlibrary(ggplot2)\np_hist &lt;- ggplot(df, aes(sleep_total)) +\n  geom_histogram(binwidth = 1)\np_hist"
  },
  {
    "objectID": "tutorials/tutorial_03.html#q13-scatterplot-with-ggplot",
    "href": "tutorials/tutorial_03.html#q13-scatterplot-with-ggplot",
    "title": "Tutorial 03: Distributions",
    "section": "Q13 — Scatterplot with ggplot",
    "text": "Q13 — Scatterplot with ggplot\nMake a scatterplot of bodywt (x) vs sleep_total (y), \\(log_{10}\\) scale on x, with a smooth trend (Read info to understand what these terms mean), by replacing the ＿＿ with the correct answer. Save the plot to p_scatter. Fill the scatterplot with any color of your choice!\n\n\n\n\n\n\nNoteInfo\n\n\n\nInfo : ggplot refers to the ggplot2 package in R, a powerful tool for creating statistical graphics.\n\n\n\n\n\n\n\n\nNoteInfo\n\n\n\nInfo : 1) A \\(log_{10}\\) scale on the x-axis transforms the x values before plotting.This spreads out small values and compresses very large ones. As an exercise, also try removing that argument and see how much harder it is to visualize the data without it.\n\nA smooth trend line is added along the points by using geom_smooth(). This leads to better visualization of trends in the data.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLook up how to make scatterplots with ggplot.\n\n\n\n\nlibrary(ggplot2)\np_scatter &lt;- ggplot(df, aes(bodywt, sleep_total)) +\n  geom_point() +\n  scale_x_log10() +\n  geom_smooth(se = FALSE)\np_scatter\nlibrary(ggplot2)\np_scatter &lt;- ggplot(df, aes(bodywt, sleep_total)) +\n  geom_point() +\n  scale_x_log10() +\n  geom_smooth(se = FALSE)\np_scatter"
  },
  {
    "objectID": "tutorials/tutorial_03.html#q14-mean-and-standard-deviation",
    "href": "tutorials/tutorial_03.html#q14-mean-and-standard-deviation",
    "title": "Tutorial 03: Distributions",
    "section": "Q14 — Mean and Standard Deviation",
    "text": "Q14 — Mean and Standard Deviation\nCompute the population mean and standard deviation of sleep_total. Save them in mu and sigma. Note that x is the vector containing sleep data pulled from the dataset.\n\n\n\n\n\n\nNoteInfo\n\n\n\nInfo : This and the following examples illustrate the power of the Central Limit Theorem (CLT). CLT states that for a sufficiently large sample size, the sampling distribution of the sample mean will be approximately normal, regardless of the shape of the original population distribution.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nR has direct commands to compute mean and standard deviation. Look into those.\n\n\n\n\nmu &lt;- mean(x)\nsigma &lt;- sd(x)\nmu &lt;- mean(x)\nsigma &lt;- sd(x)"
  },
  {
    "objectID": "tutorials/tutorial_03.html#q15-sample-mean-and-sample-standard-deviation",
    "href": "tutorials/tutorial_03.html#q15-sample-mean-and-sample-standard-deviation",
    "title": "Tutorial 03: Distributions",
    "section": "Q15 — Sample Mean and Sample Standard Deviation",
    "text": "Q15 — Sample Mean and Sample Standard Deviation\nB = 200 samples of size n = 10 with replacement from x are stored in means_10. Compute the following: m_10 = Mean of means_n10, s_10 = Standard Deviation of means_n10\n\n\n\n\n\n\n\n\n\n\n\n\nR has direct commands to compute mean and standard deviation. Look into those.\n\n\n\n\nmeans_n10 &lt;- replicate(B, mean(sample(x, n, replace = TRUE)))\nm_10  &lt;- mean(means_n10)\nm_10\ns_10    &lt;- sd(means_n10)\ns_10\nmeans_n10 &lt;- replicate(B, mean(sample(x, n, replace = TRUE)))\nm_10  &lt;- mean(means_n10)\nm_10\ns_10    &lt;- sd(means_n10)\ns_10"
  },
  {
    "objectID": "tutorials/tutorial_03.html#q16-visualizing-the-distribution",
    "href": "tutorials/tutorial_03.html#q16-visualizing-the-distribution",
    "title": "Tutorial 03: Distributions",
    "section": "Q16 — Visualizing the Distribution",
    "text": "Q16 — Visualizing the Distribution\nMake a histogram of means_n10 (binwidth = 0.5), and add a vertical dashed red line at the population mean mu. Save the plot in plot_clt and print it. Fill the plot with any color of your choice!\n\n\n\n\n\n\nNoteInfo\n\n\n\nNotice the distribution of the sample mean here and see if it resembles a normal distribution. Which theorem is in play here?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRefer to previous exercises for learning how to plot a histogram. To draw a vertical line at a certain intercept, use the ggplot command- geom_vline .\n\n\n\n\nlibrary(ggplot2)\np_clt_n10 &lt;- ggplot(data.frame(m = means_n10), aes(m)) +\n  geom_histogram(binwidth = 0.5, fill = \"grey80\", color = \"white\") +\n  geom_vline(xintercept = mu, linetype = 2, color = \"red\") +\n  labs(x = \"sample mean (n=10)\", y = \"count\",\n                title = \"Sampling distribution of the mean (n = 10)\") +\n  theme_minimal()\np_clt_n10\nlibrary(ggplot2)\np_clt_n10 &lt;- ggplot(data.frame(m = means_n10), aes(m)) +\n  geom_histogram(binwidth = 0.5, fill = \"grey80\", color = \"white\") +\n  geom_vline(xintercept = mu, linetype = 2, color = \"red\") +\n  labs(x = \"sample mean (n=10)\", y = \"count\",\n                title = \"Sampling distribution of the mean (n = 10)\") +\n  theme_minimal()\np_clt_n10"
  },
  {
    "objectID": "practice/prac_01.html#q2",
    "href": "practice/prac_01.html#q2",
    "title": "Practice Module 01",
    "section": "Q2 — Build a vector of multiples",
    "text": "Q2 — Build a vector of multiples\nCreate my_vec containing all multiples of 5 from 5 to 100 (inclusive) using seq() (don’t type them out).\n\n\n\n\n\n\nNoteInfo\n\n\n\nRemember: in R, seq() is a versatile function that is used to generate a sequence of numbers with specified starting, ending points or a desired length.\n\n\n\n\n\n\n\n\n\n\n\nLearn how to use the seq() function\n\n\n\n\nmy_vec &lt;-seq(5, 100, by = 5)\nmy_vec &lt;-seq(5, 100, by = 5)"
  },
  {
    "objectID": "practice/prac_01.html#q3-transformed-histogram",
    "href": "practice/prac_01.html#q3-transformed-histogram",
    "title": "Practice Module 01",
    "section": "Q3 —Transformed Histogram",
    "text": "Q3 —Transformed Histogram\nGenerate a histogram of log\\(_{10}\\)(cars$dist) with breaks = 10.\n\n\n\n\n\n\nNoteInfo\n\n\n\nRemember: in R, the breaks argument in a hist command controls the number of bars, cells or bins of the histogram!\n\n\n\n\n\n\n\n\n\n\n\nLearn how to incorporate a breaks argument in the hist command you are already familiar with!\n\n\n\n\nhist(log10(cars$dist), breaks = 10)\nhist(log10(cars$dist), breaks = 10)"
  },
  {
    "objectID": "practice/prac_01.html#q4-find-the-average",
    "href": "practice/prac_01.html#q4-find-the-average",
    "title": "Practice Module 01",
    "section": "Q4 — Find the average",
    "text": "Q4 — Find the average\nCompute the mean of the vector c(2, 4, 6, 8, 10).\nYour answer should be stored in a variable called avg_val.\n\n\n\n\n\n\n\n\n\nUse the mean() function: mean(c(…))\n\n\n\n\navg_val &lt;- mean(c(2, 4, 6, 8, 10))\navg_val &lt;- mean(c(2, 4, 6, 8, 10))"
  },
  {
    "objectID": "practice/prac_01.html#q3",
    "href": "practice/prac_01.html#q3",
    "title": "Practice Module 01",
    "section": "Q5 — Sequence of evens",
    "text": "Q5 — Sequence of evens\nCreate evens_20_60 with all even numbers from 20 to 60 inclusive using seq().\n\n\n\n\n\n\n\n\n\nseq(20, 60, by = 2)\n\n\n\n\nevens_20_60 &lt;- seq(20, 60, by = 2)\nevens_20_60 &lt;- seq(20, 60, by = 2)"
  },
  {
    "objectID": "practice/prac_01.html#q4",
    "href": "practice/prac_01.html#q4",
    "title": "Practice Module 01",
    "section": "Q6 — Tiny calculator function",
    "text": "Q6 — Tiny calculator function\nWrite mini_calc(a, b) that returns a named numeric vector with: sum = a+b, diff = a-b, prod = a*b, quot = a/b (NA if b==0).\n\n\n\n\n\n\n\n\n\nReturn like c(sum=…, diff=…, prod=…, quot=…). Handle b==0 for quot.\n\n\n\n\nmini_calc &lt;- function(a, b) {\n  c(\n    sum  = a + b,\n    diff = a - b,\n    prod = a * b,\n    quot = if (b == 0) NA_real_ else a / b\n  )\n}\nmini_calc &lt;- function(a, b) {\n  c(\n    sum  = a + b,\n    diff = a - b,\n    prod = a * b,\n    quot = if (b == 0) NA_real_ else a / b\n  )\n}"
  }
]